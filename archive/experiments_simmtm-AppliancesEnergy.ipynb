{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shamvinc/ssl_time_series/mvts_transformer/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    os.chdir('src')\n",
    "except:\n",
    "    pass\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../img/img_0.PNG\"  width=\"1000\" height=\"240\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SimMTM is a simple self-supervised learning framework for Masked Time-Series Modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "from datasets.datasplit import split_dataset\n",
    "from datasets.data import data_factory, Normalizer, TSRegressionArchive, CSVRegressionArchive\n",
    "from datasets.datasplit import split_dataset\n",
    "from datasets.dataset import collate_superv\n",
    "from models.ts_transformer import model_factory\n",
    "from models.loss import get_loss_module, contrastive_loss\n",
    "from optimizers import get_optimizer\n",
    "\n",
    "from options import Options\n",
    "from running import setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Masked Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/img_1.PNG\"  width=\"900\" height=\"240\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/img_2.PNG\"  width=\"900\" height=\"240\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Masking is not a good choice to learn a good representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"../img/img_3.PNG\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therefore, we randomly mask a sequence of points in a serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def geom_noise_mask_single(L, lm, masking_ratio):\n",
    "    \"\"\"\n",
    "    Randomly create a boolean mask of length `L`, consisting of subsequences of average length lm, masking with 0s a `masking_ratio`\n",
    "    proportion of the sequence L. The length of masking subsequences and intervals follow a geometric distribution.\n",
    "    Args:\n",
    "        L: length of mask and sequence to be masked\n",
    "        lm: average length of masking subsequences (streaks of 0s)\n",
    "        masking_ratio: proportion of L to be masked\n",
    "\n",
    "    Returns:\n",
    "        (L,) boolean numpy array intended to mask ('drop') with 0s a sequence of length L\n",
    "    \"\"\"\n",
    "    keep_mask = np.ones(L, dtype=bool)\n",
    "    p_m = 1 / lm  # probability of each masking sequence stopping. parameter of geometric distribution.\n",
    "    p_u = p_m * masking_ratio / (1 - masking_ratio)  # probability of each unmasked sequence stopping. parameter of geometric distribution.\n",
    "    p = [p_m, p_u]\n",
    "\n",
    "    # Start in state 0 with masking_ratio probability\n",
    "    state = int(np.random.rand() > masking_ratio)  # state 0 means masking, 1 means not masking\n",
    "    for i in range(L):\n",
    "        keep_mask[i] = state  # here it happens that state and masking value corresponding to state are identical\n",
    "        if np.random.rand() < p[state]:\n",
    "            state = 1 - state\n",
    "\n",
    "    return keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SimMTM ultilizes both contrastive learning and mask modeling to learn the data representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Contrastive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"../img/img_5.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The contrastive loss is the following: (Eq. 8 in the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><img src=\"../img/img_6.PNG\"/><center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def demo_contrastive_loss(z, batch_size):\n",
    "    s = s.squeeze(-1) \n",
    "\n",
    "    B = s.shape[0]\n",
    "    v = s.reshape(B, -1)\n",
    "\n",
    "    norm_v = torch.norm(v, p=2, dim=-1).unsqueeze(-1)\n",
    "    v = v/norm_v\n",
    "    u = torch.transpose(v, 0, 1)\n",
    "\n",
    "    R = torch.matmul(v,u)\n",
    "\n",
    " \n",
    "    R = torch.exp(R/tau) # (batch + mask size) x (batch + mask size)\n",
    "    \n",
    "    # number of masks\n",
    "    M = B//batch_size\n",
    "    mask = torch.eye(batch_size, device=R.device).repeat_interleave(M,dim=0).repeat_interleave(M,dim=1)\n",
    "\n",
    "    denom = R * (torch.ones_like(R) - torch.eye(R.shape[0], device=R.device))\n",
    "\n",
    "    denom = R.sum(-1).unsqueeze(-1)\n",
    "\n",
    "    loss = torch.log(R/denom)\n",
    "    \n",
    "\n",
    "    loss = (loss * (mask - torch.eye(R.shape[0], device=R.device))).sum(1)/(M-1) # except no masked unit\n",
    "    loss = loss.mean(0)\n",
    "    \n",
    "    return -loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Masked Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimMTM proposes to recover a time serie by the weighted sum of multiple masked points, which eases the reconstruction task by assembling ruined but complementary temporal variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"../img/img_4.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DemoSimMTMTransformerEncoder(nn.Module):\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: (batch_size, seq_length, feat_dim) torch tensor of masked features (input)\n",
    "            padding_masks: (batch_size, seq_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "        Returns:\n",
    "            output: (batch_size, seq_length, feat_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        # permute because pytorch convention for transformers is [seq_length, batch_size, feat_dim]. padding_masks [batch_size, feat_dim]\n",
    "        _x = X\n",
    "     \n",
    "        for i in range(self.temporal_unit):\n",
    "            mask = geom_noise_mask_single(X.shape[0] * X.shape[1] * X.shape[2], 5, 0.3)\n",
    "            mask = mask.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "            mask = torch.from_numpy(mask).to(X.device)\n",
    "            x_masked = mask * X\n",
    "            _x = torch.cat([_x, x_masked], axis=-1) # [batch_size, seq_length, feat_dim * temporal_unit]\n",
    "    \n",
    "        \n",
    "        _x = _x.reshape(X.shape[0] * (self.temporal_unit + 1), X.shape[1], X.shape[2])\n",
    "  \n",
    "\n",
    "        inp = _x.permute(1, 0, 2)\n",
    "        inp = self.project_inp(inp) * math.sqrt(self.d_model)  # [seq_length, batch_size, d_model] project input vectors to d_model dimensional space\n",
    "        inp = self.pos_enc(inp)  # add positional encoding\n",
    "\n",
    "        \n",
    "        output = self.transformer_encoder(inp)  # (seq_length, batch_size, d_model)\n",
    "        output = self.act(output)  # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = output.permute(1, 0, 2)  # (batch_size, seq_length, d_model)\n",
    "        output = self.dropout1(output)\n",
    "\n",
    "        z_hat = self.project(output)\n",
    "        # Most probably defining a Linear(d_model,feat_dim) vectorizes the operation over (seq_length, batch_size).\n",
    "        output = self.output_layer(z_hat)  # (batch_size, seq_length, feat_dim)\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def project(self, z, tau=0.02):\n",
    "        _z = z.transpose(1, 2) # [batch_size, d_model, seq_length]\n",
    "        s = self.projector_layer(_z) # [batch_size, d_model, 1]\n",
    "        s = s.squeeze(-1) \n",
    "\n",
    "        B = s.shape[0]\n",
    "        v = s.reshape(B, -1)\n",
    "\n",
    "        norm_v = torch.norm(v, p=2, dim=-1).unsqueeze(-1)\n",
    "        v = v/norm_v\n",
    "        u = torch.transpose(v, 0, 1)\n",
    "        \n",
    "        R = torch.matmul(v,u)\n",
    "     \n",
    "  \n",
    "        R = torch.exp(R/tau) # (batch + mask size) x (batch + mask size)\n",
    "        R = R * (torch.ones_like(R) - torch.eye(R.shape[0], device=R.device)) # zero out the weight of no masked component\n",
    "        R = R/R.sum(-1).unsqueeze(-1)\n",
    "        M = self.temporal_unit + 1\n",
    "        R = R[::M] # extract every no mask unit # (batch size) x (batch + mask size)\n",
    "\n",
    "        z_hat = (R.unsqueeze(-1).unsqueeze(-1) * z.unsqueeze(0)).sum(1) \n",
    "        return z_hat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 00:55:10,648 | INFO : Stored configuration file in '../experiments/_2023-08-21_00-55-10_Btc'\n"
     ]
    }
   ],
   "source": [
    "args = Options().parse()  # `argsparse` object\n",
    "# args.data_dir = '../datasets/BeijingPM25Quality'\n",
    "args.data_dir = '../datasets/AppliancesEnergy'\n",
    " \n",
    "args.task = 'regression'\n",
    "args.output_dir = '../experiments'\n",
    "config = setup(args)\n",
    "# config = setup(args)  # configuration dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [00:03, 29.85it/s]\n",
      "66it [00:01, 37.69it/s] \n"
     ]
    }
   ],
   "source": [
    "data = TSRegressionArchive(config['data_dir'], pattern='TRAIN', config=config)\n",
    "test_data = TSRegressionArchive(config['data_dir'], pattern='TEST', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_14</th>\n",
       "      <th>dim_15</th>\n",
       "      <th>dim_16</th>\n",
       "      <th>dim_17</th>\n",
       "      <th>dim_18</th>\n",
       "      <th>dim_19</th>\n",
       "      <th>dim_20</th>\n",
       "      <th>dim_21</th>\n",
       "      <th>dim_22</th>\n",
       "      <th>dim_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-2.153832</td>\n",
       "      <td>-0.259319</td>\n",
       "      <td>-2.121628</td>\n",
       "      <td>-0.999057</td>\n",
       "      <td>-1.514857</td>\n",
       "      <td>-0.514935</td>\n",
       "      <td>-1.837894</td>\n",
       "      <td>-1.126190</td>\n",
       "      <td>-0.656912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267595</td>\n",
       "      <td>-1.654712</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.464965</td>\n",
       "      <td>-0.418045</td>\n",
       "      <td>0.330620</td>\n",
       "      <td>-1.948513</td>\n",
       "      <td>1.202557</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-1.981361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-2.089203</td>\n",
       "      <td>-0.288860</td>\n",
       "      <td>-2.089363</td>\n",
       "      <td>-0.999057</td>\n",
       "      <td>-1.497081</td>\n",
       "      <td>-0.514935</td>\n",
       "      <td>-1.823090</td>\n",
       "      <td>-1.126190</td>\n",
       "      <td>-0.672042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234318</td>\n",
       "      <td>-1.654712</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.456310</td>\n",
       "      <td>-0.436693</td>\n",
       "      <td>0.342184</td>\n",
       "      <td>-1.915849</td>\n",
       "      <td>1.134967</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-1.973379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-2.056059</td>\n",
       "      <td>-0.303630</td>\n",
       "      <td>-2.027255</td>\n",
       "      <td>-0.999057</td>\n",
       "      <td>-1.464492</td>\n",
       "      <td>-0.528758</td>\n",
       "      <td>-1.786821</td>\n",
       "      <td>-1.088955</td>\n",
       "      <td>-0.668638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199456</td>\n",
       "      <td>-1.640794</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.456310</td>\n",
       "      <td>-0.455342</td>\n",
       "      <td>0.353748</td>\n",
       "      <td>-1.883185</td>\n",
       "      <td>1.067377</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-1.965397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.287474</td>\n",
       "      <td>-2.006345</td>\n",
       "      <td>-0.330216</td>\n",
       "      <td>-1.962726</td>\n",
       "      <td>-0.999057</td>\n",
       "      <td>-1.464492</td>\n",
       "      <td>-0.528758</td>\n",
       "      <td>-1.758695</td>\n",
       "      <td>-1.126190</td>\n",
       "      <td>-0.675447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151917</td>\n",
       "      <td>-1.616753</td>\n",
       "      <td>-0.472082</td>\n",
       "      <td>-0.464965</td>\n",
       "      <td>-0.473990</td>\n",
       "      <td>0.365312</td>\n",
       "      <td>-1.850521</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-1.957415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.323280</td>\n",
       "      <td>-1.988116</td>\n",
       "      <td>-0.343509</td>\n",
       "      <td>-1.907877</td>\n",
       "      <td>-0.999057</td>\n",
       "      <td>-1.464492</td>\n",
       "      <td>-0.544116</td>\n",
       "      <td>-1.726867</td>\n",
       "      <td>-1.126190</td>\n",
       "      <td>-0.686795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123394</td>\n",
       "      <td>-1.628141</td>\n",
       "      <td>-0.472082</td>\n",
       "      <td>-0.464965</td>\n",
       "      <td>-0.492638</td>\n",
       "      <td>0.376875</td>\n",
       "      <td>-1.817857</td>\n",
       "      <td>0.932197</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-1.949433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.104462</td>\n",
       "      <td>-1.923486</td>\n",
       "      <td>-0.166268</td>\n",
       "      <td>-1.946594</td>\n",
       "      <td>-0.907768</td>\n",
       "      <td>-1.286734</td>\n",
       "      <td>-0.408963</td>\n",
       "      <td>-1.883045</td>\n",
       "      <td>-1.126190</td>\n",
       "      <td>-0.545512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437149</td>\n",
       "      <td>-1.565509</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.503523</td>\n",
       "      <td>-0.371424</td>\n",
       "      <td>0.307492</td>\n",
       "      <td>-2.111834</td>\n",
       "      <td>1.540506</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-2.101089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.144247</td>\n",
       "      <td>-2.054402</td>\n",
       "      <td>-0.181038</td>\n",
       "      <td>-2.034514</td>\n",
       "      <td>-0.872534</td>\n",
       "      <td>-1.464492</td>\n",
       "      <td>-0.456574</td>\n",
       "      <td>-1.853438</td>\n",
       "      <td>-1.126190</td>\n",
       "      <td>-0.577475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405457</td>\n",
       "      <td>-1.589549</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.489359</td>\n",
       "      <td>-0.380749</td>\n",
       "      <td>0.312118</td>\n",
       "      <td>-2.079170</td>\n",
       "      <td>1.472917</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-2.077144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.166129</td>\n",
       "      <td>-2.130632</td>\n",
       "      <td>-0.210578</td>\n",
       "      <td>-2.113562</td>\n",
       "      <td>-0.939800</td>\n",
       "      <td>-1.545471</td>\n",
       "      <td>-0.487290</td>\n",
       "      <td>-1.899329</td>\n",
       "      <td>-1.088955</td>\n",
       "      <td>-0.592606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375349</td>\n",
       "      <td>-1.602835</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.482277</td>\n",
       "      <td>-0.390073</td>\n",
       "      <td>0.316744</td>\n",
       "      <td>-2.046506</td>\n",
       "      <td>1.405327</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-2.053198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.209893</td>\n",
       "      <td>-2.213490</td>\n",
       "      <td>-0.259319</td>\n",
       "      <td>-2.146632</td>\n",
       "      <td>-0.970229</td>\n",
       "      <td>-1.556334</td>\n",
       "      <td>-0.487290</td>\n",
       "      <td>-1.862320</td>\n",
       "      <td>-1.107573</td>\n",
       "      <td>-0.618706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346826</td>\n",
       "      <td>-1.616753</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.482277</td>\n",
       "      <td>-0.399397</td>\n",
       "      <td>0.321369</td>\n",
       "      <td>-2.013842</td>\n",
       "      <td>1.337737</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-2.029252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.229785</td>\n",
       "      <td>-2.186975</td>\n",
       "      <td>-0.259319</td>\n",
       "      <td>-2.164378</td>\n",
       "      <td>-0.999057</td>\n",
       "      <td>-1.534608</td>\n",
       "      <td>-0.487290</td>\n",
       "      <td>-1.862320</td>\n",
       "      <td>-1.107573</td>\n",
       "      <td>-0.641403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299287</td>\n",
       "      <td>-1.654712</td>\n",
       "      <td>-0.454857</td>\n",
       "      <td>-0.482277</td>\n",
       "      <td>-0.408721</td>\n",
       "      <td>0.325995</td>\n",
       "      <td>-1.981178</td>\n",
       "      <td>1.270147</td>\n",
       "      <td>0.106478</td>\n",
       "      <td>-2.005306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13680 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dim_0     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
       "0  -0.269570 -2.153832 -0.259319 -2.121628 -0.999057 -1.514857 -0.514935   \n",
       "0  -0.269570 -2.089203 -0.288860 -2.089363 -0.999057 -1.497081 -0.514935   \n",
       "0  -0.269570 -2.056059 -0.303630 -2.027255 -0.999057 -1.464492 -0.528758   \n",
       "0  -0.287474 -2.006345 -0.330216 -1.962726 -0.999057 -1.464492 -0.528758   \n",
       "0  -0.323280 -1.988116 -0.343509 -1.907877 -0.999057 -1.464492 -0.544116   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "94 -0.104462 -1.923486 -0.166268 -1.946594 -0.907768 -1.286734 -0.408963   \n",
       "94 -0.144247 -2.054402 -0.181038 -2.034514 -0.872534 -1.464492 -0.456574   \n",
       "94 -0.166129 -2.130632 -0.210578 -2.113562 -0.939800 -1.545471 -0.487290   \n",
       "94 -0.209893 -2.213490 -0.259319 -2.146632 -0.970229 -1.556334 -0.487290   \n",
       "94 -0.229785 -2.186975 -0.259319 -2.164378 -0.999057 -1.534608 -0.487290   \n",
       "\n",
       "       dim_7     dim_8     dim_9  ...    dim_14    dim_15    dim_16    dim_17  \\\n",
       "0  -1.837894 -1.126190 -0.656912  ...  0.267595 -1.654712 -0.454857 -0.464965   \n",
       "0  -1.823090 -1.126190 -0.672042  ...  0.234318 -1.654712 -0.454857 -0.456310   \n",
       "0  -1.786821 -1.088955 -0.668638  ...  0.199456 -1.640794 -0.454857 -0.456310   \n",
       "0  -1.758695 -1.126190 -0.675447  ...  0.151917 -1.616753 -0.472082 -0.464965   \n",
       "0  -1.726867 -1.126190 -0.686795  ...  0.123394 -1.628141 -0.472082 -0.464965   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "94 -1.883045 -1.126190 -0.545512  ...  0.437149 -1.565509 -0.454857 -0.503523   \n",
       "94 -1.853438 -1.126190 -0.577475  ...  0.405457 -1.589549 -0.454857 -0.489359   \n",
       "94 -1.899329 -1.088955 -0.592606  ...  0.375349 -1.602835 -0.454857 -0.482277   \n",
       "94 -1.862320 -1.107573 -0.618706  ...  0.346826 -1.616753 -0.454857 -0.482277   \n",
       "94 -1.862320 -1.107573 -0.641403  ...  0.299287 -1.654712 -0.454857 -0.482277   \n",
       "\n",
       "      dim_18    dim_19    dim_20    dim_21    dim_22    dim_23  \n",
       "0  -0.418045  0.330620 -1.948513  1.202557  0.106478 -1.981361  \n",
       "0  -0.436693  0.342184 -1.915849  1.134967  0.106478 -1.973379  \n",
       "0  -0.455342  0.353748 -1.883185  1.067377  0.106478 -1.965397  \n",
       "0  -0.473990  0.365312 -1.850521  0.999787  0.106478 -1.957415  \n",
       "0  -0.492638  0.376875 -1.817857  0.932197  0.106478 -1.949433  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "94 -0.371424  0.307492 -2.111834  1.540506  0.106478 -2.101089  \n",
       "94 -0.380749  0.312118 -2.079170  1.472917  0.106478 -2.077144  \n",
       "94 -0.390073  0.316744 -2.046506  1.405327  0.106478 -2.053198  \n",
       "94 -0.399397  0.321369 -2.013842  1.337737  0.106478 -2.029252  \n",
       "94 -0.408721  0.325995 -1.981178  1.270147  0.106478 -2.005306  \n",
       "\n",
       "[13680 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices, _ = split_dataset(data_indices=data.all_IDs,\n",
    "                                                         validation_method='ShuffleSplit',\n",
    "                                                         n_splits=1,\n",
    "                                                         validation_ratio=0.2,\n",
    "                                                         test_set_ratio=0,  # used only if test_indices not explicitly specified\n",
    "                                                         test_indices=None,\n",
    "                                                         random_seed=1337,\n",
    "                                                         labels=None)\n",
    "train_indices = train_indices[0]\n",
    "val_indices = val_indices[0]\n",
    "test_indices = np.array(test_data.all_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(config['normalization'])\n",
    "data.feature_df = normalizer.normalize(data.feature_df)\n",
    "test_data.feature_df = normalizer.normalize(test_data.feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "config['task'] = 'simmtm'\n",
    "config['normalization_layer'] = 'BatchNorm'\n",
    "config['out_len'] = 1\n",
    "config['out_dim'] = 1\n",
    "config['d_model'] = 8\n",
    "config['dim_feedforward'] = 16\n",
    "config['num_heads'] = 4\n",
    "config['num_layers'] = 2\n",
    "\n",
    "# SimMTMTransformerEncoder\n",
    "from models.ts_transformer import model_factory\n",
    "model = model_factory(config, data)\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "model.tau = 0.05\n",
    "min_tau = 0.05\n",
    "model.mask_length = data.feature_df.loc[0].shape[0]//4\n",
    "print(model.mask_length)\n",
    "model.mask_ratio = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "max_len = data.feature_df.loc[0].shape[0]\n",
    "train_dataloader = DataLoader(train_indices, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_indices, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_indices, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch 0 - Best Validation loss: 10000000000.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "max_epoch = 0\n",
    "best_loss = 1e10\n",
    "best_model = copy.deepcopy(model)\n",
    "best_epoch = 0\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "while i < max_epoch:\n",
    "    train_loss = { \"loss\": [], \"loss_mse\": [], \"loss_con\": []}\n",
    "    progress_bar = tqdm(train_dataloader)\n",
    "    \n",
    "    for IDs in progress_bar:\n",
    "        model.train()\n",
    "        X = torch.tensor(data.feature_df.loc[IDs].to_numpy()).to(device)\n",
    "        X = X.float()\n",
    "        X = X.reshape(-1, max_len, X.shape[-1])\n",
    "        \n",
    "        pred, R, w1, w2, norm = model(X)  # (batch_size, padded_length, feat_dim)\n",
    "        \n",
    "        loss_mse = loss_fn(pred, X) \n",
    "\n",
    "        loss_con = contrastive_loss(R, X.shape[0])\n",
    "        \n",
    "        loss_norm =  norm.mean()\n",
    "\n",
    "        loss = 1/(w1.pow(2)) * loss_mse + 1/(w2.pow(2)) * loss_con + torch.log(w1) + torch.log(w2) \n",
    "  \n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=4.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_description(\"Epoch {0} - Training loss: {1:.2f} - MSE loss: {2:.2f} - Contrastive loss: {3:.2f} - norm loss: {3:.2f}\".format(i, \n",
    "                loss.cpu().detach().numpy().item(), loss_mse.cpu().detach().numpy().item(), \n",
    "                loss_con.cpu().detach().numpy().item(), loss_norm.cpu().detach().numpy().item())) \n",
    "        train_loss[\"loss\"].append(loss)\n",
    "        train_loss[\"loss_mse\"].append(loss_mse)\n",
    "        train_loss[\"loss_con\"].append(loss_con)\n",
    "    model.tau = max(model.tau * 0.98, min_tau)\n",
    "        \n",
    "    \n",
    "    val_loss = { \"loss\": [], \"loss_mse\": [], \"loss_con\": []}\n",
    "    for IDs in val_dataloader:\n",
    "        model.eval()\n",
    "        X = torch.tensor(data.feature_df.loc[IDs].to_numpy()).to(device)\n",
    "        X = X.float()\n",
    "        X = X.reshape(-1, max_len, X.shape[-1])\n",
    "        \n",
    "                \n",
    "        pred, R, w1, w2, norm = model(X.float())  # (batch_size, padded_length, feat_dim)\n",
    "        \n",
    "        loss_mse = loss_fn(pred, X) \n",
    "\n",
    "        loss_con = contrastive_loss(R, X.shape[0])\n",
    "\n",
    "        loss = 1/(w1.pow(2)) * loss_mse + 1/(w2.pow(2)) * loss_con + torch.log(w1) + torch.log(w2)\n",
    "        \n",
    "        val_loss[\"loss\"].append(loss)\n",
    "        val_loss[\"loss_mse\"].append(loss_mse)\n",
    "        val_loss[\"loss_con\"].append(loss_con)\n",
    "    \n",
    "    train_loss[\"loss\"] = torch.tensor(train_loss[\"loss\"]).mean()\n",
    "    train_loss[\"loss_mse\"] = torch.tensor(train_loss[\"loss_mse\"]).mean()\n",
    "    train_loss[\"loss_con\"] = torch.tensor(train_loss[\"loss_con\"]).mean()\n",
    "    val_loss[\"loss\"] = torch.tensor(val_loss[\"loss\"]).mean()\n",
    "    val_loss[\"loss_mse\"] = torch.tensor(val_loss[\"loss_mse\"]).mean()\n",
    "    val_loss[\"loss_con\"] = torch.tensor(val_loss[\"loss_con\"]).mean()\n",
    "    \n",
    "    if val_loss[\"loss\"] < best_loss and model.tau == min_tau:\n",
    "        best_loss = val_loss[\"loss\"]\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_epoch = i\n",
    "    \n",
    "    progress_bar.write(\"Epoch {0} - Training loss: {1:.2f} {2:.2f} {3:.2f} - Validation loss: {4:.2f} {5:.2f} {6:.2f}\".format(i, \n",
    "            train_loss[\"loss\"].cpu().detach().numpy().item(), train_loss[\"loss_mse\"].cpu().detach().numpy().item(), train_loss[\"loss_con\"].cpu().detach().numpy().item(),\n",
    "            val_loss[\"loss\"].cpu().detach().numpy().item(), val_loss[\"loss_mse\"].cpu().detach().numpy().item(), val_loss[\"loss_con\"].cpu().detach().numpy().item()))\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "tqdm.write(\"Best Epoch {} - Best Validation loss: {}\".format(best_epoch, best_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace the output layer for downstream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_model = copy.deepcopy(best_model)\n",
    "# finetune_model.predict_layer1 = nn.Linear(finetune_model.max_len , 1)\n",
    "# out_size = data.labels_df.shape[1]\n",
    "# hid_size = finetune_model.d_model \n",
    "# finetune_model.predict_layer2 = nn.Linear(hid_size , out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(finetune_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 162.58544921875: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 49.48it/s]\n",
      "Epoch 1 - Training loss: 243.96957397460938: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.24it/s]\n",
      "Epoch 2 - Training loss: 213.84176635742188: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.08it/s]\n",
      "Epoch 3 - Training loss: 154.29847717285156: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 51.15it/s]\n",
      "Epoch 4 - Training loss: 183.98291015625: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 51.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 186.9484100341797 - Validation loss: 269.57745361328125\n",
      "Epoch 1 - Training loss: 219.54864501953125 - Validation loss: 268.97491455078125\n",
      "Epoch 2 - Training loss: 207.2030792236328 - Validation loss: 268.5617370605469\n",
      "Epoch 3 - Training loss: 182.6446533203125 - Validation loss: 268.2022399902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 - Training loss: 171.26467895507812: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 54.08it/s]\n",
      "Epoch 6 - Training loss: 230.4658660888672: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 50.83it/s]\n",
      "Epoch 7 - Training loss: 199.80856323242188: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 49.49it/s]\n",
      "Epoch 8 - Training loss: 184.15869140625: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 51.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training loss: 194.3675994873047 - Validation loss: 267.8271484375\n",
      "Epoch 5 - Training loss: 188.67726135253906 - Validation loss: 267.3499450683594\n",
      "Epoch 6 - Training loss: 212.71441650390625 - Validation loss: 266.77508544921875\n",
      "Epoch 7 - Training loss: 199.86184692382812 - Validation loss: 266.00897216796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 - Training loss: 151.30294799804688: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 49.64it/s]\n",
      "Epoch 10 - Training loss: 228.3866424560547: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.34it/s]\n",
      "Epoch 11 - Training loss: 184.88449096679688: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.72it/s]\n",
      "Epoch 12 - Training loss: 167.44949340820312: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training loss: 192.90440368652344 - Validation loss: 265.0201721191406\n",
      "Epoch 9 - Training loss: 178.9453125 - Validation loss: 263.71234130859375\n",
      "Epoch 10 - Training loss: 209.99520874023438 - Validation loss: 262.2259216308594\n",
      "Epoch 11 - Training loss: 191.51895141601562 - Validation loss: 260.31243896484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 - Training loss: 195.3590087890625: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 51.74it/s]\n",
      "Epoch 14 - Training loss: 247.85679626464844: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.45it/s]\n",
      "Epoch 15 - Training loss: 199.4271697998047: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 53.66it/s]\n",
      "Epoch 16 - Training loss: 143.93807983398438: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training loss: 183.1023712158203 - Validation loss: 258.3831787109375\n",
      "Epoch 13 - Training loss: 193.28158569335938 - Validation loss: 255.53868103027344\n",
      "Epoch 14 - Training loss: 213.42108154296875 - Validation loss: 252.7337646484375\n",
      "Epoch 15 - Training loss: 193.1585693359375 - Validation loss: 249.6211700439453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 - Training loss: 165.24781799316406: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.97it/s]\n",
      "Epoch 18 - Training loss: 171.3300018310547: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.66it/s]\n",
      "Epoch 19 - Training loss: 159.215576171875: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 55.54it/s]\n",
      "Epoch 20 - Training loss: 176.01229858398438: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.73it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training loss: 169.48931884765625 - Validation loss: 246.40943908691406\n",
      "Epoch 17 - Training loss: 176.81326293945312 - Validation loss: 242.8572235107422\n",
      "Epoch 18 - Training loss: 177.8387451171875 - Validation loss: 239.03875732421875\n",
      "Epoch 19 - Training loss: 170.74839782714844 - Validation loss: 235.30709838867188\n",
      "Epoch 20 - Training loss: 176.03323364257812 - Validation loss: 230.9837646484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training loss: 217.00390625: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 55.38it/s]\n",
      "Epoch 22 - Training loss: 194.1215057373047: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.84it/s]\n",
      "Epoch 23 - Training loss: 185.36749267578125: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.38it/s]\n",
      "Epoch 24 - Training loss: 148.9766845703125: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.09it/s]\n",
      "Epoch 25 - Training loss: 149.23326110839844: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.83it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training loss: 191.33609008789062 - Validation loss: 226.02120971679688\n",
      "Epoch 22 - Training loss: 178.3848114013672 - Validation loss: 221.01690673828125\n",
      "Epoch 23 - Training loss: 173.7371368408203 - Validation loss: 215.99879455566406\n",
      "Epoch 24 - Training loss: 156.65777587890625 - Validation loss: 211.6431121826172\n",
      "Epoch 25 - Training loss: 154.71615600585938 - Validation loss: 208.03341674804688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Training loss: 198.11318969726562: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.60it/s]\n",
      "Epoch 27 - Training loss: 103.04106140136719: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.29it/s]\n",
      "Epoch 28 - Training loss: 110.2955551147461: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 39.96it/s]\n",
      "Epoch 29 - Training loss: 122.35226440429688: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 48.61it/s]\n",
      "Epoch 30 - Training loss: 130.1192169189453:   0%|                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Training loss: 173.50259399414062 - Validation loss: 202.22799682617188\n",
      "Epoch 27 - Training loss: 129.92593383789062 - Validation loss: 197.62168884277344\n",
      "Epoch 28 - Training loss: 131.73497009277344 - Validation loss: 192.7593994140625\n",
      "Epoch 29 - Training loss: 132.4754638671875 - Validation loss: 187.29469299316406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Training loss: 184.55319213867188: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.09it/s]\n",
      "Epoch 31 - Training loss: 149.25164794921875: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.36it/s]\n",
      "Epoch 32 - Training loss: 116.53792572021484: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.22it/s]\n",
      "Epoch 33 - Training loss: 143.57579040527344: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.29it/s]\n",
      "Epoch 34 - Training loss: 83.19367980957031: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.65it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Training loss: 157.33621215820312 - Validation loss: 181.60037231445312\n",
      "Epoch 31 - Training loss: 139.78909301757812 - Validation loss: 176.5928192138672\n",
      "Epoch 32 - Training loss: 122.56369018554688 - Validation loss: 169.49876403808594\n",
      "Epoch 33 - Training loss: 132.39254760742188 - Validation loss: 161.95822143554688\n",
      "Epoch 34 - Training loss: 106.37459564208984 - Validation loss: 157.71885681152344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Training loss: 108.37255096435547: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.49it/s]\n",
      "Epoch 36 - Training loss: 87.14864349365234: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.56it/s]\n",
      "Epoch 37 - Training loss: 123.72533416748047: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.10it/s]\n",
      "Epoch 38 - Training loss: 161.6456756591797: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 54.74it/s]\n",
      "Epoch 39 - Training loss: 114.82554626464844: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.42it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Training loss: 111.35604858398438 - Validation loss: 152.18524169921875\n",
      "Epoch 36 - Training loss: 102.05886840820312 - Validation loss: 146.02099609375\n",
      "Epoch 37 - Training loss: 113.10193634033203 - Validation loss: 141.18301391601562\n",
      "Epoch 38 - Training loss: 130.55978393554688 - Validation loss: 135.8275146484375\n",
      "Epoch 39 - Training loss: 107.00192260742188 - Validation loss: 131.5140838623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Training loss: 124.34139251708984: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.64it/s]\n",
      "Epoch 41 - Training loss: 75.47732543945312: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 54.78it/s]\n",
      "Epoch 42 - Training loss: 110.15771484375: 100%|██████████████████████████████████████| 2/2 [00:00<00:00, 54.87it/s]\n",
      "Epoch 43 - Training loss: 61.66210174560547: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 54.70it/s]\n",
      "Epoch 44 - Training loss: 78.46890258789062: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 54.55it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Training loss: 109.37985229492188 - Validation loss: 126.36265563964844\n",
      "Epoch 41 - Training loss: 84.24246978759766 - Validation loss: 122.29254913330078\n",
      "Epoch 42 - Training loss: 94.82038116455078 - Validation loss: 115.14083099365234\n",
      "Epoch 43 - Training loss: 72.39570617675781 - Validation loss: 112.10725402832031\n",
      "Epoch 44 - Training loss: 76.93592834472656 - Validation loss: 106.96403503417969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 - Training loss: 71.62398529052734: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 53.98it/s]\n",
      "Epoch 46 - Training loss: 89.33470153808594: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.31it/s]\n",
      "Epoch 47 - Training loss: 80.78094482421875: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 51.05it/s]\n",
      "Epoch 48 - Training loss: 29.328834533691406: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.71it/s]\n",
      "Epoch 49 - Training loss: 62.157554626464844: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 - Training loss: 72.70980072021484 - Validation loss: 102.52354431152344\n",
      "Epoch 46 - Training loss: 78.46673583984375 - Validation loss: 96.92147064208984\n",
      "Epoch 47 - Training loss: 70.41504669189453 - Validation loss: 91.70185089111328\n",
      "Epoch 48 - Training loss: 51.45787811279297 - Validation loss: 86.17292022705078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50 - Training loss: 83.6813735961914: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 53.20it/s]\n",
      "Epoch 51 - Training loss: 18.83868408203125: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 49.80it/s]\n",
      "Epoch 52 - Training loss: 31.812881469726562: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 49.99it/s]\n",
      "Epoch 53 - Training loss: 59.81045150756836: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 - Training loss: 57.956825256347656 - Validation loss: 79.37214660644531\n",
      "Epoch 50 - Training loss: 63.435062408447266 - Validation loss: 74.82440948486328\n",
      "Epoch 51 - Training loss: 37.53828811645508 - Validation loss: 68.17162322998047\n",
      "Epoch 52 - Training loss: 38.33171844482422 - Validation loss: 61.91176223754883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54 - Training loss: 29.977493286132812: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.71it/s]\n",
      "Epoch 55 - Training loss: 43.3243522644043: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 51.00it/s]\n",
      "Epoch 56 - Training loss: 34.01066589355469: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.14it/s]\n",
      "Epoch 57 - Training loss: 39.10072326660156: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 51.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 - Training loss: 51.67734146118164 - Validation loss: 57.414154052734375\n",
      "Epoch 54 - Training loss: 33.885047912597656 - Validation loss: 53.06871032714844\n",
      "Epoch 55 - Training loss: 38.249488830566406 - Validation loss: 49.2081184387207\n",
      "Epoch 56 - Training loss: 35.87453079223633 - Validation loss: 46.66842269897461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58 - Training loss: 47.47494125366211: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 50.53it/s]\n",
      "Epoch 59 - Training loss: 16.08990478515625: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 51.45it/s]\n",
      "Epoch 60 - Training loss: 43.9863395690918: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 52.04it/s]\n",
      "Epoch 61 - Training loss: 15.98536205291748: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 - Training loss: 35.85618209838867 - Validation loss: 43.825889587402344\n",
      "Epoch 58 - Training loss: 38.80445861816406 - Validation loss: 40.832725524902344\n",
      "Epoch 59 - Training loss: 23.550487518310547 - Validation loss: 38.39033889770508\n",
      "Epoch 60 - Training loss: 35.99459457397461 - Validation loss: 36.63348388671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62 - Training loss: 40.62083435058594: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 51.96it/s]\n",
      "Epoch 63 - Training loss: 18.334917068481445: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.93it/s]\n",
      "Epoch 64 - Training loss: 17.317184448242188: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.82it/s]\n",
      "Epoch 65 - Training loss: 18.203407287597656: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 - Training loss: 22.635469436645508 - Validation loss: 35.30989074707031\n",
      "Epoch 62 - Training loss: 32.18497848510742 - Validation loss: 35.2609748840332\n",
      "Epoch 63 - Training loss: 23.07387924194336 - Validation loss: 33.862945556640625\n",
      "Epoch 64 - Training loss: 20.088848114013672 - Validation loss: 32.610599517822266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66 - Training loss: 27.31048583984375: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 53.46it/s]\n",
      "Epoch 67 - Training loss: 24.58619499206543: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 53.82it/s]\n",
      "Epoch 68 - Training loss: 23.486392974853516: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.21it/s]\n",
      "Epoch 69 - Training loss: 17.505598068237305: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.98it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 - Training loss: 19.778156280517578 - Validation loss: 32.48920822143555\n",
      "Epoch 66 - Training loss: 26.036949157714844 - Validation loss: 33.09881591796875\n",
      "Epoch 67 - Training loss: 21.698482513427734 - Validation loss: 33.5000114440918\n",
      "Epoch 68 - Training loss: 20.277332305908203 - Validation loss: 33.8072624206543\n",
      "Epoch 69 - Training loss: 16.788663864135742 - Validation loss: 33.79048156738281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 - Training loss: 18.55821990966797: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 51.55it/s]\n",
      "Epoch 71 - Training loss: 26.945701599121094: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.56it/s]\n",
      "Epoch 72 - Training loss: 28.705785751342773: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.44it/s]\n",
      "Epoch 73 - Training loss: 22.75886344909668: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 53.11it/s]\n",
      "Epoch 74 - Training loss: 36.10460662841797: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.67it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - Training loss: 18.898513793945312 - Validation loss: 33.422977447509766\n",
      "Epoch 71 - Training loss: 22.35212516784668 - Validation loss: 33.02914810180664\n",
      "Epoch 72 - Training loss: 22.224275588989258 - Validation loss: 31.736759185791016\n",
      "Epoch 73 - Training loss: 22.938209533691406 - Validation loss: 31.079082489013672\n",
      "Epoch 74 - Training loss: 26.609739303588867 - Validation loss: 30.765005111694336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 - Training loss: 26.52535629272461: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.62it/s]\n",
      "Epoch 76 - Training loss: 28.04988670349121: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.71it/s]\n",
      "Epoch 77 - Training loss: 34.609405517578125: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.66it/s]\n",
      "Epoch 78 - Training loss: 18.97789764404297: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.39it/s]\n",
      "Epoch 79 - Training loss: 13.267958641052246: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.14it/s]\n",
      "Epoch 80 - Training loss: 17.88681983947754:   0%|                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 - Training loss: 23.30147361755371 - Validation loss: 28.691091537475586\n",
      "Epoch 76 - Training loss: 24.31298828125 - Validation loss: 26.957618713378906\n",
      "Epoch 77 - Training loss: 27.57733154296875 - Validation loss: 27.9455623626709\n",
      "Epoch 78 - Training loss: 21.544506072998047 - Validation loss: 28.660207748413086\n",
      "Epoch 79 - Training loss: 15.372241973876953 - Validation loss: 29.775346755981445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80 - Training loss: 8.96826457977295: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 54.37it/s]\n",
      "Epoch 81 - Training loss: 21.278074264526367: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.77it/s]\n",
      "Epoch 82 - Training loss: 12.92313289642334: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 54.36it/s]\n",
      "Epoch 83 - Training loss: 25.39032554626465: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.91it/s]\n",
      "Epoch 84 - Training loss: 16.275957107543945: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.57it/s]\n",
      "Epoch 85 - Training loss: 19.320663452148438:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - Training loss: 13.427541732788086 - Validation loss: 30.129854202270508\n",
      "Epoch 81 - Training loss: 20.32022476196289 - Validation loss: 31.561405181884766\n",
      "Epoch 82 - Training loss: 15.510414123535156 - Validation loss: 31.964946746826172\n",
      "Epoch 83 - Training loss: 22.98802947998047 - Validation loss: 30.90745735168457\n",
      "Epoch 84 - Training loss: 15.906929016113281 - Validation loss: 29.998531341552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85 - Training loss: 11.623591423034668: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.54it/s]\n",
      "Epoch 86 - Training loss: 20.174053192138672: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.58it/s]\n",
      "Epoch 87 - Training loss: 27.067365646362305: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 57.01it/s]\n",
      "Epoch 88 - Training loss: 15.062899589538574: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.57it/s]\n",
      "Epoch 89 - Training loss: 15.103239059448242: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.99it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 - Training loss: 15.472127914428711 - Validation loss: 28.949296951293945\n",
      "Epoch 86 - Training loss: 18.024181365966797 - Validation loss: 27.7235107421875\n",
      "Epoch 87 - Training loss: 21.175777435302734 - Validation loss: 26.5753116607666\n",
      "Epoch 88 - Training loss: 15.674163818359375 - Validation loss: 25.037517547607422\n",
      "Epoch 89 - Training loss: 14.963090896606445 - Validation loss: 23.20470428466797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90 - Training loss: 29.996490478515625: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.40it/s]\n",
      "Epoch 91 - Training loss: 11.651896476745605: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.38it/s]\n",
      "Epoch 92 - Training loss: 20.54909896850586: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.07it/s]\n",
      "Epoch 93 - Training loss: 18.134702682495117: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.70it/s]\n",
      "Epoch 94 - Training loss: 9.314913749694824: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.71it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 - Training loss: 21.490718841552734 - Validation loss: 22.29348373413086\n",
      "Epoch 91 - Training loss: 11.335250854492188 - Validation loss: 22.186458587646484\n",
      "Epoch 92 - Training loss: 19.581117630004883 - Validation loss: 22.675424575805664\n",
      "Epoch 93 - Training loss: 17.03508758544922 - Validation loss: 24.043432235717773\n",
      "Epoch 94 - Training loss: 12.695184707641602 - Validation loss: 25.193790435791016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95 - Training loss: 23.023181915283203: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.71it/s]\n",
      "Epoch 96 - Training loss: 17.486080169677734: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.21it/s]\n",
      "Epoch 97 - Training loss: 15.111437797546387: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.80it/s]\n",
      "Epoch 98 - Training loss: 21.582191467285156: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.05it/s]\n",
      "Epoch 99 - Training loss: 16.7762508392334: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 55.81it/s]\n",
      "Epoch 100 - Training loss: 21.531375885009766:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 - Training loss: 18.265178680419922 - Validation loss: 26.423364639282227\n",
      "Epoch 96 - Training loss: 16.988327026367188 - Validation loss: 28.41969108581543\n",
      "Epoch 97 - Training loss: 16.74444580078125 - Validation loss: 28.984542846679688\n",
      "Epoch 98 - Training loss: 22.25795555114746 - Validation loss: 27.308330535888672\n",
      "Epoch 99 - Training loss: 15.164043426513672 - Validation loss: 24.597272872924805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 - Training loss: 13.465749740600586: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.38it/s]\n",
      "Epoch 101 - Training loss: 9.74726390838623: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.93it/s]\n",
      "Epoch 102 - Training loss: 20.65361785888672: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.84it/s]\n",
      "Epoch 103 - Training loss: 14.335006713867188: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.82it/s]\n",
      "Epoch 104 - Training loss: 13.598228454589844: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.03it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 - Training loss: 17.49856185913086 - Validation loss: 21.908037185668945\n",
      "Epoch 101 - Training loss: 13.383262634277344 - Validation loss: 19.549034118652344\n",
      "Epoch 102 - Training loss: 19.586328506469727 - Validation loss: 18.492820739746094\n",
      "Epoch 103 - Training loss: 13.908712387084961 - Validation loss: 18.064001083374023\n",
      "Epoch 104 - Training loss: 13.96010684967041 - Validation loss: 18.83076286315918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105 - Training loss: 12.82806396484375: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.93it/s]\n",
      "Epoch 106 - Training loss: 32.775543212890625: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.16it/s]\n",
      "Epoch 107 - Training loss: 12.212196350097656: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.11it/s]\n",
      "Epoch 108 - Training loss: 10.36642837524414: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.82it/s]\n",
      "Epoch 109 - Training loss: 22.91461753845215: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.15it/s]\n",
      "Epoch 110 - Training loss: 12.094075202941895:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 - Training loss: 13.305716514587402 - Validation loss: 19.656667709350586\n",
      "Epoch 106 - Training loss: 25.963394165039062 - Validation loss: 20.483938217163086\n",
      "Epoch 107 - Training loss: 14.113056182861328 - Validation loss: 20.448823928833008\n",
      "Epoch 108 - Training loss: 12.28256893157959 - Validation loss: 21.136178970336914\n",
      "Epoch 109 - Training loss: 17.029216766357422 - Validation loss: 22.033096313476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110 - Training loss: 11.512313842773438: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.01it/s]\n",
      "Epoch 111 - Training loss: 23.209671020507812: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.55it/s]\n",
      "Epoch 112 - Training loss: 11.661222457885742: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.02it/s]\n",
      "Epoch 113 - Training loss: 13.177501678466797: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.55it/s]\n",
      "Epoch 114 - Training loss: 15.015275955200195: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.85it/s]\n",
      "Epoch 115 - Training loss: 16.7357177734375:   0%|                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 - Training loss: 11.803194046020508 - Validation loss: 21.303585052490234\n",
      "Epoch 111 - Training loss: 18.579912185668945 - Validation loss: 21.097225189208984\n",
      "Epoch 112 - Training loss: 15.787991523742676 - Validation loss: 21.207494735717773\n",
      "Epoch 113 - Training loss: 12.915653228759766 - Validation loss: 21.01564598083496\n",
      "Epoch 114 - Training loss: 14.30449390411377 - Validation loss: 20.622594833374023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115 - Training loss: 16.262331008911133: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 50.80it/s]\n",
      "Epoch 116 - Training loss: 8.249713897705078: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.99it/s]\n",
      "Epoch 117 - Training loss: 26.37458610534668: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.78it/s]\n",
      "Epoch 118 - Training loss: 27.205678939819336: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.31it/s]\n",
      "Epoch 119 - Training loss: 20.149051666259766: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.61it/s]\n",
      "Epoch 120 - Training loss: 15.652176856994629:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 - Training loss: 16.4990234375 - Validation loss: 20.06017303466797\n",
      "Epoch 116 - Training loss: 12.926928520202637 - Validation loss: 20.01369285583496\n",
      "Epoch 117 - Training loss: 19.069828033447266 - Validation loss: 20.302616119384766\n",
      "Epoch 118 - Training loss: 21.902912139892578 - Validation loss: 20.922765731811523\n",
      "Epoch 119 - Training loss: 18.310636520385742 - Validation loss: 20.857336044311523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120 - Training loss: 13.991249084472656: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.06it/s]\n",
      "Epoch 121 - Training loss: 25.807655334472656: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.25it/s]\n",
      "Epoch 122 - Training loss: 8.828668594360352: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.10it/s]\n",
      "Epoch 123 - Training loss: 12.437782287597656: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.29it/s]\n",
      "Epoch 124 - Training loss: 11.408583641052246: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.67it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 - Training loss: 14.821712493896484 - Validation loss: 21.660062789916992\n",
      "Epoch 121 - Training loss: 19.466379165649414 - Validation loss: 22.538183212280273\n",
      "Epoch 122 - Training loss: 11.491591453552246 - Validation loss: 22.876567840576172\n",
      "Epoch 123 - Training loss: 14.345450401306152 - Validation loss: 22.28602409362793\n",
      "Epoch 124 - Training loss: 15.400781631469727 - Validation loss: 21.58322525024414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125 - Training loss: 4.87385892868042: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.02it/s]\n",
      "Epoch 126 - Training loss: 21.797714233398438: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.57it/s]\n",
      "Epoch 127 - Training loss: 9.538751602172852: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.23it/s]\n",
      "Epoch 128 - Training loss: 9.437049865722656: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.43it/s]\n",
      "Epoch 129 - Training loss: 20.39407730102539: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.62it/s]\n",
      "Epoch 130 - Training loss: 15.558248519897461:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 - Training loss: 11.343017578125 - Validation loss: 21.569503784179688\n",
      "Epoch 126 - Training loss: 20.314781188964844 - Validation loss: 20.960458755493164\n",
      "Epoch 127 - Training loss: 9.33187484741211 - Validation loss: 21.038257598876953\n",
      "Epoch 128 - Training loss: 11.672727584838867 - Validation loss: 21.579938888549805\n",
      "Epoch 129 - Training loss: 18.862815856933594 - Validation loss: 22.440744400024414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130 - Training loss: 10.935701370239258: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.74it/s]\n",
      "Epoch 131 - Training loss: 15.10580825805664: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 48.25it/s]\n",
      "Epoch 132 - Training loss: 7.072853088378906: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 46.38it/s]\n",
      "Epoch 133 - Training loss: 8.81968879699707: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.99it/s]\n",
      "Epoch 134 - Training loss: 20.747669219970703: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.00it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 - Training loss: 13.24697494506836 - Validation loss: 23.18331527709961\n",
      "Epoch 131 - Training loss: 14.987098693847656 - Validation loss: 24.270824432373047\n",
      "Epoch 132 - Training loss: 9.603650093078613 - Validation loss: 24.262481689453125\n",
      "Epoch 133 - Training loss: 10.976604461669922 - Validation loss: 23.471336364746094\n",
      "Epoch 134 - Training loss: 17.96708106994629 - Validation loss: 23.219472885131836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135 - Training loss: 11.275142669677734: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.17it/s]\n",
      "Epoch 136 - Training loss: 8.780800819396973: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.01it/s]\n",
      "Epoch 137 - Training loss: 12.56702995300293: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.02it/s]\n",
      "Epoch 138 - Training loss: 24.477508544921875: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.99it/s]\n",
      "Epoch 139 - Training loss: 17.019777297973633: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.02it/s]\n",
      "Epoch 140 - Training loss: 13.35884952545166:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 - Training loss: 12.393696784973145 - Validation loss: 22.477558135986328\n",
      "Epoch 136 - Training loss: 12.982887268066406 - Validation loss: 21.24087905883789\n",
      "Epoch 137 - Training loss: 12.529274940490723 - Validation loss: 20.142005920410156\n",
      "Epoch 138 - Training loss: 16.77733039855957 - Validation loss: 19.999486923217773\n",
      "Epoch 139 - Training loss: 15.918484687805176 - Validation loss: 20.182052612304688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140 - Training loss: 10.28669261932373: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.63it/s]\n",
      "Epoch 141 - Training loss: 16.91179656982422: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.52it/s]\n",
      "Epoch 142 - Training loss: 20.013280868530273: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.58it/s]\n",
      "Epoch 143 - Training loss: 9.482311248779297: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.08it/s]\n",
      "Epoch 144 - Training loss: 16.595001220703125: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.58it/s]\n",
      "Epoch 145 - Training loss: 17.479568481445312:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 - Training loss: 11.822771072387695 - Validation loss: 20.58588218688965\n",
      "Epoch 141 - Training loss: 12.870416641235352 - Validation loss: 20.875741958618164\n",
      "Epoch 142 - Training loss: 21.16647720336914 - Validation loss: 20.774967193603516\n",
      "Epoch 143 - Training loss: 10.66209602355957 - Validation loss: 21.246234893798828\n",
      "Epoch 144 - Training loss: 14.765057563781738 - Validation loss: 20.96959114074707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145 - Training loss: 12.817618370056152: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.94it/s]\n",
      "Epoch 146 - Training loss: 11.624397277832031: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.89it/s]\n",
      "Epoch 147 - Training loss: 16.39309310913086: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.28it/s]\n",
      "Epoch 148 - Training loss: 7.605399131774902: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.31it/s]\n",
      "Epoch 149 - Training loss: 16.49701690673828: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.60it/s]\n",
      "Epoch 150 - Training loss: 10.598352432250977:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 - Training loss: 15.14859390258789 - Validation loss: 20.416128158569336\n",
      "Epoch 146 - Training loss: 13.360764503479004 - Validation loss: 20.869665145874023\n",
      "Epoch 147 - Training loss: 14.307929992675781 - Validation loss: 20.264080047607422\n",
      "Epoch 148 - Training loss: 13.593425750732422 - Validation loss: 19.300817489624023\n",
      "Epoch 149 - Training loss: 14.805073738098145 - Validation loss: 18.88707160949707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150 - Training loss: 16.510814666748047: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.58it/s]\n",
      "Epoch 151 - Training loss: 19.462614059448242: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.99it/s]\n",
      "Epoch 152 - Training loss: 15.477518081665039: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.42it/s]\n",
      "Epoch 153 - Training loss: 6.402005672454834: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.80it/s]\n",
      "Epoch 154 - Training loss: 10.720168113708496: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.08it/s]\n",
      "Epoch 155 - Training loss: 12.872557640075684:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 - Training loss: 13.554583549499512 - Validation loss: 18.717269897460938\n",
      "Epoch 151 - Training loss: 14.227897644042969 - Validation loss: 18.510744094848633\n",
      "Epoch 152 - Training loss: 12.158666610717773 - Validation loss: 18.79706382751465\n",
      "Epoch 153 - Training loss: 9.532302856445312 - Validation loss: 18.96121597290039\n",
      "Epoch 154 - Training loss: 12.855730056762695 - Validation loss: 18.520971298217773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155 - Training loss: 13.882445335388184: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.52it/s]\n",
      "Epoch 156 - Training loss: 7.373441219329834: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.65it/s]\n",
      "Epoch 157 - Training loss: 8.019262313842773: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 43.04it/s]\n",
      "Epoch 158 - Training loss: 9.171380996704102: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.12it/s]\n",
      "Epoch 159 - Training loss: 16.164794921875: 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 56.76it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 - Training loss: 13.377501487731934 - Validation loss: 19.106948852539062\n",
      "Epoch 156 - Training loss: 12.31491756439209 - Validation loss: 19.392837524414062\n",
      "Epoch 157 - Training loss: 12.648871421813965 - Validation loss: 18.3752498626709\n",
      "Epoch 158 - Training loss: 11.488266944885254 - Validation loss: 18.093807220458984\n",
      "Epoch 159 - Training loss: 11.800566673278809 - Validation loss: 17.529542922973633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160 - Training loss: 11.798450469970703: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.93it/s]\n",
      "Epoch 161 - Training loss: 5.099750518798828: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.60it/s]\n",
      "Epoch 162 - Training loss: 11.158160209655762: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.09it/s]\n",
      "Epoch 163 - Training loss: 14.741393089294434: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.35it/s]\n",
      "Epoch 164 - Training loss: 6.99593448638916: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.16it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 - Training loss: 11.037668228149414 - Validation loss: 17.625661849975586\n",
      "Epoch 161 - Training loss: 9.659984588623047 - Validation loss: 17.889141082763672\n",
      "Epoch 162 - Training loss: 10.682855606079102 - Validation loss: 17.87017059326172\n",
      "Epoch 163 - Training loss: 11.793649673461914 - Validation loss: 18.147518157958984\n",
      "Epoch 164 - Training loss: 10.132364273071289 - Validation loss: 18.53609275817871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165 - Training loss: 19.928558349609375: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 51.84it/s]\n",
      "Epoch 166 - Training loss: 13.670863151550293: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.33it/s]\n",
      "Epoch 167 - Training loss: 6.129752159118652: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.18it/s]\n",
      "Epoch 168 - Training loss: 14.183939933776855: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.94it/s]\n",
      "Epoch 169 - Training loss: 14.481428146362305: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.92it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 - Training loss: 14.857695579528809 - Validation loss: 18.37118148803711\n",
      "Epoch 166 - Training loss: 13.307369232177734 - Validation loss: 18.29216957092285\n",
      "Epoch 167 - Training loss: 8.842083930969238 - Validation loss: 18.469453811645508\n",
      "Epoch 168 - Training loss: 15.369768142700195 - Validation loss: 18.502761840820312\n",
      "Epoch 169 - Training loss: 12.382576942443848 - Validation loss: 19.15439224243164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170 - Training loss: 10.782861709594727: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.21it/s]\n",
      "Epoch 171 - Training loss: 18.70819664001465: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.94it/s]\n",
      "Epoch 172 - Training loss: 11.534042358398438: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.99it/s]\n",
      "Epoch 173 - Training loss: 15.739923477172852: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.70it/s]\n",
      "Epoch 174 - Training loss: 7.418032646179199: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.29it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 - Training loss: 11.209001541137695 - Validation loss: 18.62995147705078\n",
      "Epoch 171 - Training loss: 15.981328010559082 - Validation loss: 18.3636474609375\n",
      "Epoch 172 - Training loss: 11.293859481811523 - Validation loss: 17.875905990600586\n",
      "Epoch 173 - Training loss: 14.66091251373291 - Validation loss: 17.442401885986328\n",
      "Epoch 174 - Training loss: 9.354324340820312 - Validation loss: 15.962930679321289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175 - Training loss: 12.409468650817871: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.14it/s]\n",
      "Epoch 176 - Training loss: 12.009279251098633: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.03it/s]\n",
      "Epoch 177 - Training loss: 14.835660934448242: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 51.88it/s]\n",
      "Epoch 178 - Training loss: 17.52185821533203: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.19it/s]\n",
      "Epoch 179 - Training loss: 27.755285263061523: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.57it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 - Training loss: 13.807085990905762 - Validation loss: 14.99425983428955\n",
      "Epoch 176 - Training loss: 10.689990997314453 - Validation loss: 14.827237129211426\n",
      "Epoch 177 - Training loss: 13.593182563781738 - Validation loss: 14.74407958984375\n",
      "Epoch 178 - Training loss: 14.55361270904541 - Validation loss: 14.745161056518555\n",
      "Epoch 179 - Training loss: 22.578811645507812 - Validation loss: 15.242640495300293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180 - Training loss: 15.878096580505371: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 47.94it/s]\n",
      "Epoch 181 - Training loss: 13.779083251953125: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.48it/s]\n",
      "Epoch 182 - Training loss: 12.206085205078125: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.25it/s]\n",
      "Epoch 183 - Training loss: 7.83637809753418: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.18it/s]\n",
      "Epoch 184 - Training loss: 12.832996368408203: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.10it/s]\n",
      "Epoch 185 - Training loss: 12.231487274169922:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 - Training loss: 15.495285034179688 - Validation loss: 16.495864868164062\n",
      "Epoch 181 - Training loss: 14.269417762756348 - Validation loss: 17.868728637695312\n",
      "Epoch 182 - Training loss: 13.996790885925293 - Validation loss: 19.668415069580078\n",
      "Epoch 183 - Training loss: 9.83513069152832 - Validation loss: 20.4976749420166\n",
      "Epoch 184 - Training loss: 10.498701095581055 - Validation loss: 21.219179153442383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185 - Training loss: 14.489053726196289: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.35it/s]\n",
      "Epoch 186 - Training loss: 16.081165313720703: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.81it/s]\n",
      "Epoch 187 - Training loss: 10.433561325073242: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.93it/s]\n",
      "Epoch 188 - Training loss: 22.25263786315918: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.31it/s]\n",
      "Epoch 189 - Training loss: 17.44886016845703: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.29it/s]\n",
      "Epoch 190 - Training loss: 13.424647331237793:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 - Training loss: 13.360270500183105 - Validation loss: 21.655004501342773\n",
      "Epoch 186 - Training loss: 17.61558723449707 - Validation loss: 21.495107650756836\n",
      "Epoch 187 - Training loss: 8.784446716308594 - Validation loss: 20.199886322021484\n",
      "Epoch 188 - Training loss: 19.88098907470703 - Validation loss: 19.144699096679688\n",
      "Epoch 189 - Training loss: 14.039400100708008 - Validation loss: 18.18797492980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Training loss: 10.122783660888672: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.89it/s]\n",
      "Epoch 191 - Training loss: 13.542609214782715: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.91it/s]\n",
      "Epoch 192 - Training loss: 15.898009300231934: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.81it/s]\n",
      "Epoch 193 - Training loss: 12.809809684753418: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.97it/s]\n",
      "Epoch 194 - Training loss: 21.18529510498047: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.21it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Training loss: 11.77371597290039 - Validation loss: 17.617122650146484\n",
      "Epoch 191 - Training loss: 12.66621208190918 - Validation loss: 17.23444366455078\n",
      "Epoch 192 - Training loss: 14.51264762878418 - Validation loss: 16.812761306762695\n",
      "Epoch 193 - Training loss: 11.796597480773926 - Validation loss: 16.679508209228516\n",
      "Epoch 194 - Training loss: 16.047712326049805 - Validation loss: 16.626951217651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195 - Training loss: 6.604288101196289: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 47.75it/s]\n",
      "Epoch 196 - Training loss: 8.066970825195312: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.83it/s]\n",
      "Epoch 197 - Training loss: 4.670875072479248: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.59it/s]\n",
      "Epoch 198 - Training loss: 8.889869689941406: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.76it/s]\n",
      "Epoch 199 - Training loss: 19.97269058227539: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.60it/s]\n",
      "Epoch 200 - Training loss: 13.855205535888672:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 - Training loss: 9.864885330200195 - Validation loss: 16.621450424194336\n",
      "Epoch 196 - Training loss: 9.4114990234375 - Validation loss: 16.524030685424805\n",
      "Epoch 197 - Training loss: 9.584651947021484 - Validation loss: 16.917034149169922\n",
      "Epoch 198 - Training loss: 9.546954154968262 - Validation loss: 17.46876335144043\n",
      "Epoch 199 - Training loss: 15.464400291442871 - Validation loss: 19.0067195892334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Training loss: 8.097769737243652: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.71it/s]\n",
      "Epoch 201 - Training loss: 18.041492462158203: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.83it/s]\n",
      "Epoch 202 - Training loss: 40.32027816772461: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.59it/s]\n",
      "Epoch 203 - Training loss: 24.665740966796875: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.10it/s]\n",
      "Epoch 204 - Training loss: 12.015081405639648: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.98it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Training loss: 10.97648811340332 - Validation loss: 19.160863876342773\n",
      "Epoch 201 - Training loss: 13.72439956665039 - Validation loss: 19.211936950683594\n",
      "Epoch 202 - Training loss: 25.96700668334961 - Validation loss: 18.6109561920166\n",
      "Epoch 203 - Training loss: 17.337642669677734 - Validation loss: 17.63429069519043\n",
      "Epoch 204 - Training loss: 12.184661865234375 - Validation loss: 17.673816680908203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 205 - Training loss: 9.414490699768066: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.08it/s]\n",
      "Epoch 206 - Training loss: 7.9576921463012695: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.70it/s]\n",
      "Epoch 207 - Training loss: 13.824244499206543: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.03it/s]\n",
      "Epoch 208 - Training loss: 9.601438522338867: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.93it/s]\n",
      "Epoch 209 - Training loss: 17.679054260253906: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.12it/s]\n",
      "Epoch 210 - Training loss: 10.596879959106445:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205 - Training loss: 12.279666900634766 - Validation loss: 18.17154884338379\n",
      "Epoch 206 - Training loss: 8.38862419128418 - Validation loss: 18.702943801879883\n",
      "Epoch 207 - Training loss: 12.86073112487793 - Validation loss: 19.390865325927734\n",
      "Epoch 208 - Training loss: 8.6165189743042 - Validation loss: 19.76180076599121\n",
      "Epoch 209 - Training loss: 14.113495826721191 - Validation loss: 20.02134895324707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 210 - Training loss: 21.688007354736328: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.31it/s]\n",
      "Epoch 211 - Training loss: 10.575289726257324: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.82it/s]\n",
      "Epoch 212 - Training loss: 8.535587310791016: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.52it/s]\n",
      "Epoch 213 - Training loss: 6.156908988952637: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.98it/s]\n",
      "Epoch 214 - Training loss: 30.124874114990234: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.30it/s]\n",
      "Epoch 215 - Training loss: 9.194246292114258:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210 - Training loss: 16.142444610595703 - Validation loss: 20.38372802734375\n",
      "Epoch 211 - Training loss: 11.203102111816406 - Validation loss: 20.10726547241211\n",
      "Epoch 212 - Training loss: 10.168227195739746 - Validation loss: 19.02408218383789\n",
      "Epoch 213 - Training loss: 8.147683143615723 - Validation loss: 18.075748443603516\n",
      "Epoch 214 - Training loss: 21.770790100097656 - Validation loss: 17.776464462280273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 215 - Training loss: 8.318109512329102: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.81it/s]\n",
      "Epoch 216 - Training loss: 11.909055709838867: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.11it/s]\n",
      "Epoch 217 - Training loss: 24.27564811706543: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.61it/s]\n",
      "Epoch 218 - Training loss: 6.931887626647949: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.48it/s]\n",
      "Epoch 219 - Training loss: 5.131809711456299: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.05it/s]\n",
      "Epoch 220 - Training loss: 8.649560928344727:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215 - Training loss: 8.75617790222168 - Validation loss: 17.569101333618164\n",
      "Epoch 216 - Training loss: 10.464424133300781 - Validation loss: 17.427461624145508\n",
      "Epoch 217 - Training loss: 17.9036865234375 - Validation loss: 17.632478713989258\n",
      "Epoch 218 - Training loss: 9.384771347045898 - Validation loss: 18.21049690246582\n",
      "Epoch 219 - Training loss: 7.3363542556762695 - Validation loss: 19.23196029663086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220 - Training loss: 16.643800735473633: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.77it/s]\n",
      "Epoch 221 - Training loss: 31.578243255615234: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.21it/s]\n",
      "Epoch 222 - Training loss: 6.272325038909912: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.71it/s]\n",
      "Epoch 223 - Training loss: 8.868215560913086: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 49.07it/s]\n",
      "Epoch 224 - Training loss: 11.980840682983398: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 44.80it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220 - Training loss: 12.64668083190918 - Validation loss: 20.102025985717773\n",
      "Epoch 221 - Training loss: 20.755924224853516 - Validation loss: 21.43985939025879\n",
      "Epoch 222 - Training loss: 7.79200553894043 - Validation loss: 21.748260498046875\n",
      "Epoch 223 - Training loss: 9.454575538635254 - Validation loss: 21.445919036865234\n",
      "Epoch 224 - Training loss: 9.617263793945312 - Validation loss: 20.2069034576416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 225 - Training loss: 8.947349548339844: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.02it/s]\n",
      "Epoch 226 - Training loss: 19.485942840576172: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 50.73it/s]\n",
      "Epoch 227 - Training loss: 9.93591022491455: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 50.94it/s]\n",
      "Epoch 228 - Training loss: 14.5943021774292: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 52.45it/s]\n",
      "Epoch 229 - Training loss: 7.903687953948975: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.68it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225 - Training loss: 10.707635879516602 - Validation loss: 19.053119659423828\n",
      "Epoch 226 - Training loss: 15.953800201416016 - Validation loss: 18.497228622436523\n",
      "Epoch 227 - Training loss: 11.009529113769531 - Validation loss: 18.24053382873535\n",
      "Epoch 228 - Training loss: 13.629613876342773 - Validation loss: 18.577110290527344\n",
      "Epoch 229 - Training loss: 9.835587501525879 - Validation loss: 18.664649963378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 230 - Training loss: 12.212191581726074: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.43it/s]\n",
      "Epoch 231 - Training loss: 9.57864761352539: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.91it/s]\n",
      "Epoch 232 - Training loss: 9.187061309814453: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.47it/s]\n",
      "Epoch 233 - Training loss: 11.734107971191406: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.50it/s]\n",
      "Epoch 234 - Training loss: 5.120783805847168: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.91it/s]\n",
      "Epoch 235 - Training loss: 15.587625503540039:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230 - Training loss: 10.764875411987305 - Validation loss: 18.480833053588867\n",
      "Epoch 231 - Training loss: 12.575965881347656 - Validation loss: 18.30156707763672\n",
      "Epoch 232 - Training loss: 10.548125267028809 - Validation loss: 18.09501838684082\n",
      "Epoch 233 - Training loss: 12.1585054397583 - Validation loss: 18.161191940307617\n",
      "Epoch 234 - Training loss: 10.210338592529297 - Validation loss: 18.739009857177734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 235 - Training loss: 10.121352195739746: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.42it/s]\n",
      "Epoch 236 - Training loss: 21.12372589111328: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.89it/s]\n",
      "Epoch 237 - Training loss: 7.2573089599609375: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.62it/s]\n",
      "Epoch 238 - Training loss: 14.332049369812012: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.07it/s]\n",
      "Epoch 239 - Training loss: 6.496299743652344: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.66it/s]\n",
      "Epoch 240 - Training loss: 12.343155860900879:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235 - Training loss: 12.854488372802734 - Validation loss: 19.16664695739746\n",
      "Epoch 236 - Training loss: 14.797867774963379 - Validation loss: 19.34747886657715\n",
      "Epoch 237 - Training loss: 11.573406219482422 - Validation loss: 18.33256721496582\n",
      "Epoch 238 - Training loss: 11.621809005737305 - Validation loss: 17.62974739074707\n",
      "Epoch 239 - Training loss: 8.68091106414795 - Validation loss: 17.439340591430664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 240 - Training loss: 12.567625045776367: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.32it/s]\n",
      "Epoch 241 - Training loss: 20.003719329833984: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.97it/s]\n",
      "Epoch 242 - Training loss: 8.996826171875: 100%|██████████████████████████████████████| 2/2 [00:00<00:00, 55.06it/s]\n",
      "Epoch 243 - Training loss: 12.144362449645996: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.61it/s]\n",
      "Epoch 244 - Training loss: 15.707502365112305: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.38it/s]\n",
      "Epoch 245 - Training loss: 11.354705810546875:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240 - Training loss: 12.455390930175781 - Validation loss: 17.37862777709961\n",
      "Epoch 241 - Training loss: 15.99663257598877 - Validation loss: 17.207841873168945\n",
      "Epoch 242 - Training loss: 9.88789176940918 - Validation loss: 17.733884811401367\n",
      "Epoch 243 - Training loss: 13.440790176391602 - Validation loss: 18.447004318237305\n",
      "Epoch 244 - Training loss: 13.796953201293945 - Validation loss: 18.71164321899414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 245 - Training loss: 6.965195655822754: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.79it/s]\n",
      "Epoch 246 - Training loss: 12.748598098754883: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.50it/s]\n",
      "Epoch 247 - Training loss: 18.49925422668457: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.93it/s]\n",
      "Epoch 248 - Training loss: 7.092231750488281: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.51it/s]\n",
      "Epoch 249 - Training loss: 11.940069198608398: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.44it/s]\n",
      "Epoch 250 - Training loss: 14.814705848693848:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245 - Training loss: 9.159950256347656 - Validation loss: 18.757631301879883\n",
      "Epoch 246 - Training loss: 10.242111206054688 - Validation loss: 18.578475952148438\n",
      "Epoch 247 - Training loss: 14.038530349731445 - Validation loss: 18.978107452392578\n",
      "Epoch 248 - Training loss: 9.529119491577148 - Validation loss: 19.221174240112305\n",
      "Epoch 249 - Training loss: 10.856910705566406 - Validation loss: 19.79222297668457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 250 - Training loss: 8.469991683959961: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.17it/s]\n",
      "Epoch 251 - Training loss: 11.942720413208008: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.93it/s]\n",
      "Epoch 252 - Training loss: 6.450154781341553: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.27it/s]\n",
      "Epoch 253 - Training loss: 9.656758308410645: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.25it/s]\n",
      "Epoch 254 - Training loss: 8.481100082397461: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.17it/s]\n",
      "Epoch 255 - Training loss: 17.48625373840332:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 - Training loss: 11.642349243164062 - Validation loss: 20.071693420410156\n",
      "Epoch 251 - Training loss: 10.098301887512207 - Validation loss: 20.648576736450195\n",
      "Epoch 252 - Training loss: 8.203899383544922 - Validation loss: 20.81451988220215\n",
      "Epoch 253 - Training loss: 10.645853042602539 - Validation loss: 19.976051330566406\n",
      "Epoch 254 - Training loss: 9.764785766601562 - Validation loss: 18.887361526489258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 255 - Training loss: 16.830947875976562: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.66it/s]\n",
      "Epoch 256 - Training loss: 6.224275588989258: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.26it/s]\n",
      "Epoch 257 - Training loss: 11.76264476776123: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.66it/s]\n",
      "Epoch 258 - Training loss: 8.120165824890137: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.17it/s]\n",
      "Epoch 259 - Training loss: 7.036433219909668: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.27it/s]\n",
      "Epoch 260 - Training loss: 7.747417449951172:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255 - Training loss: 17.158599853515625 - Validation loss: 18.07257080078125\n",
      "Epoch 256 - Training loss: 9.22412109375 - Validation loss: 17.425567626953125\n",
      "Epoch 257 - Training loss: 9.371143341064453 - Validation loss: 17.315343856811523\n",
      "Epoch 258 - Training loss: 10.604923248291016 - Validation loss: 17.37040901184082\n",
      "Epoch 259 - Training loss: 8.907837867736816 - Validation loss: 17.7952938079834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 260 - Training loss: 22.176918029785156: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.37it/s]\n",
      "Epoch 261 - Training loss: 14.585711479187012: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.64it/s]\n",
      "Epoch 262 - Training loss: 4.767361640930176: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.14it/s]\n",
      "Epoch 263 - Training loss: 10.383723258972168: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.36it/s]\n",
      "Epoch 264 - Training loss: 27.184951782226562: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.45it/s]\n",
      "Epoch 265 - Training loss: 9.134440422058105:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260 - Training loss: 14.962167739868164 - Validation loss: 18.719497680664062\n",
      "Epoch 261 - Training loss: 11.419978141784668 - Validation loss: 20.16931915283203\n",
      "Epoch 262 - Training loss: 7.7433295249938965 - Validation loss: 20.467769622802734\n",
      "Epoch 263 - Training loss: 10.437847137451172 - Validation loss: 21.152286529541016\n",
      "Epoch 264 - Training loss: 19.697776794433594 - Validation loss: 22.154294967651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 265 - Training loss: 15.56000804901123: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.76it/s]\n",
      "Epoch 266 - Training loss: 17.79218864440918: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.05it/s]\n",
      "Epoch 267 - Training loss: 10.691606521606445: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.48it/s]\n",
      "Epoch 268 - Training loss: 12.547419548034668: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.86it/s]\n",
      "Epoch 269 - Training loss: 13.511805534362793: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.78it/s]\n",
      "Epoch 270 - Training loss: 11.654277801513672:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265 - Training loss: 12.347224235534668 - Validation loss: 21.82781982421875\n",
      "Epoch 266 - Training loss: 14.308956146240234 - Validation loss: 21.99224090576172\n",
      "Epoch 267 - Training loss: 13.753994941711426 - Validation loss: 21.392696380615234\n",
      "Epoch 268 - Training loss: 15.106889724731445 - Validation loss: 21.044090270996094\n",
      "Epoch 269 - Training loss: 13.905112266540527 - Validation loss: 20.214292526245117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 270 - Training loss: 10.330730438232422: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.59it/s]\n",
      "Epoch 271 - Training loss: 26.604915618896484: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.45it/s]\n",
      "Epoch 272 - Training loss: 20.3013858795166: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 36.98it/s]\n",
      "Epoch 273 - Training loss: 16.644996643066406: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 50.28it/s]\n",
      "Epoch 274 - Training loss: 10.592086791992188: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270 - Training loss: 10.992504119873047 - Validation loss: 19.72759437561035\n",
      "Epoch 271 - Training loss: 19.997413635253906 - Validation loss: 19.078166961669922\n",
      "Epoch 272 - Training loss: 14.873795509338379 - Validation loss: 18.966218948364258\n",
      "Epoch 273 - Training loss: 13.351114273071289 - Validation loss: 18.5823917388916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 275 - Training loss: 17.204212188720703: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 40.84it/s]\n",
      "Epoch 276 - Training loss: 18.93145751953125: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 47.37it/s]\n",
      "Epoch 277 - Training loss: 15.775382995605469: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 51.48it/s]\n",
      "Epoch 278 - Training loss: 6.699913024902344: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 50.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274 - Training loss: 10.184209823608398 - Validation loss: 18.153291702270508\n",
      "Epoch 275 - Training loss: 15.50571346282959 - Validation loss: 17.805465698242188\n",
      "Epoch 276 - Training loss: 14.562530517578125 - Validation loss: 18.773815155029297\n",
      "Epoch 277 - Training loss: 14.459819793701172 - Validation loss: 18.922780990600586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 279 - Training loss: 18.648164749145508: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 51.80it/s]\n",
      "Epoch 280 - Training loss: 13.265300750732422: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.84it/s]\n",
      "Epoch 281 - Training loss: 51.964752197265625: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.79it/s]\n",
      "Epoch 282 - Training loss: 13.17579460144043: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.92it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278 - Training loss: 7.67074728012085 - Validation loss: 18.97933006286621\n",
      "Epoch 279 - Training loss: 15.150772094726562 - Validation loss: 19.47173309326172\n",
      "Epoch 280 - Training loss: 11.226926803588867 - Validation loss: 19.616209030151367\n",
      "Epoch 281 - Training loss: 31.696765899658203 - Validation loss: 20.051790237426758\n",
      "Epoch 282 - Training loss: 12.263792037963867 - Validation loss: 19.941640853881836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 283 - Training loss: 6.650263786315918: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.11it/s]\n",
      "Epoch 284 - Training loss: 15.697958946228027: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.17it/s]\n",
      "Epoch 285 - Training loss: 7.470161437988281: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.05it/s]\n",
      "Epoch 286 - Training loss: 10.691787719726562: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.76it/s]\n",
      "Epoch 287 - Training loss: 7.984572410583496: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.19it/s]\n",
      "Epoch 288 - Training loss: 12.951120376586914:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283 - Training loss: 7.540073871612549 - Validation loss: 19.73895835876465\n",
      "Epoch 284 - Training loss: 12.077241897583008 - Validation loss: 18.840944290161133\n",
      "Epoch 285 - Training loss: 8.66037654876709 - Validation loss: 18.4444522857666\n",
      "Epoch 286 - Training loss: 9.267866134643555 - Validation loss: 18.2561092376709\n",
      "Epoch 287 - Training loss: 11.595861434936523 - Validation loss: 18.912490844726562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 288 - Training loss: 6.16534423828125: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 53.44it/s]\n",
      "Epoch 289 - Training loss: 7.5570478439331055: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.46it/s]\n",
      "Epoch 290 - Training loss: 6.996687889099121: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.08it/s]\n",
      "Epoch 291 - Training loss: 7.143450736999512: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.16it/s]\n",
      "Epoch 292 - Training loss: 6.485596656799316: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.10it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288 - Training loss: 9.558232307434082 - Validation loss: 20.50057601928711\n",
      "Epoch 289 - Training loss: 8.762532234191895 - Validation loss: 21.283300399780273\n",
      "Epoch 290 - Training loss: 8.925163269042969 - Validation loss: 22.59425163269043\n",
      "Epoch 291 - Training loss: 11.244571685791016 - Validation loss: 23.28523063659668\n",
      "Epoch 292 - Training loss: 8.776069641113281 - Validation loss: 22.8410587310791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 293 - Training loss: 9.729564666748047: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.50it/s]\n",
      "Epoch 294 - Training loss: 15.33317756652832: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.67it/s]\n",
      "Epoch 295 - Training loss: 18.266019821166992: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.34it/s]\n",
      "Epoch 296 - Training loss: 11.66638469696045: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.81it/s]\n",
      "Epoch 297 - Training loss: 11.144340515136719: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.88it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293 - Training loss: 10.634519577026367 - Validation loss: 19.978065490722656\n",
      "Epoch 294 - Training loss: 12.922327995300293 - Validation loss: 18.471891403198242\n",
      "Epoch 295 - Training loss: 14.435568809509277 - Validation loss: 18.210939407348633\n",
      "Epoch 296 - Training loss: 9.866039276123047 - Validation loss: 17.716354370117188\n",
      "Epoch 297 - Training loss: 11.70458984375 - Validation loss: 17.11551284790039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 298 - Training loss: 20.013805389404297: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 51.02it/s]\n",
      "Epoch 299 - Training loss: 22.50001335144043: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.86it/s]\n",
      "Epoch 300 - Training loss: 14.214376449584961: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.77it/s]\n",
      "Epoch 301 - Training loss: 5.3591837882995605: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.91it/s]\n",
      "Epoch 302 - Training loss: 13.316885948181152: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.61it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298 - Training loss: 16.189605712890625 - Validation loss: 17.753047943115234\n",
      "Epoch 299 - Training loss: 15.375696182250977 - Validation loss: 18.573331832885742\n",
      "Epoch 300 - Training loss: 11.746003150939941 - Validation loss: 18.795124053955078\n",
      "Epoch 301 - Training loss: 9.027143478393555 - Validation loss: 18.606672286987305\n",
      "Epoch 302 - Training loss: 11.708736419677734 - Validation loss: 18.169815063476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 303 - Training loss: 10.711230278015137: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.48it/s]\n",
      "Epoch 304 - Training loss: 19.505207061767578: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.45it/s]\n",
      "Epoch 305 - Training loss: 13.914320945739746: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.01it/s]\n",
      "Epoch 306 - Training loss: 5.537237167358398: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.71it/s]\n",
      "Epoch 307 - Training loss: 12.890170097351074: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.90it/s]\n",
      "Epoch 308 - Training loss: 14.020702362060547:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303 - Training loss: 10.573030471801758 - Validation loss: 18.00598907470703\n",
      "Epoch 304 - Training loss: 14.190996170043945 - Validation loss: 18.281883239746094\n",
      "Epoch 305 - Training loss: 12.582719802856445 - Validation loss: 19.315038681030273\n",
      "Epoch 306 - Training loss: 9.180777549743652 - Validation loss: 19.534622192382812\n",
      "Epoch 307 - Training loss: 13.438159942626953 - Validation loss: 19.83973503112793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 308 - Training loss: 8.794881820678711: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.70it/s]\n",
      "Epoch 309 - Training loss: 7.510249614715576: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.37it/s]\n",
      "Epoch 310 - Training loss: 8.23631477355957: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 53.58it/s]\n",
      "Epoch 311 - Training loss: 14.427545547485352: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.24it/s]\n",
      "Epoch 312 - Training loss: 11.841593742370605: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.71it/s]\n",
      "Epoch 313 - Training loss: 11.595515251159668:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308 - Training loss: 11.407792091369629 - Validation loss: 19.783170700073242\n",
      "Epoch 309 - Training loss: 9.069446563720703 - Validation loss: 19.75448226928711\n",
      "Epoch 310 - Training loss: 8.629624366760254 - Validation loss: 20.507543563842773\n",
      "Epoch 311 - Training loss: 12.92248821258545 - Validation loss: 20.671632766723633\n",
      "Epoch 312 - Training loss: 9.673988342285156 - Validation loss: 20.940771102905273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 313 - Training loss: 9.830830574035645: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.94it/s]\n",
      "Epoch 314 - Training loss: 6.920518398284912: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.33it/s]\n",
      "Epoch 315 - Training loss: 12.69133186340332: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.96it/s]\n",
      "Epoch 316 - Training loss: 16.016799926757812: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 50.50it/s]\n",
      "Epoch 317 - Training loss: 11.683791160583496: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 51.76it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313 - Training loss: 10.713172912597656 - Validation loss: 20.402462005615234\n",
      "Epoch 314 - Training loss: 9.022933006286621 - Validation loss: 19.997047424316406\n",
      "Epoch 315 - Training loss: 11.541820526123047 - Validation loss: 18.934980392456055\n",
      "Epoch 316 - Training loss: 12.57675552368164 - Validation loss: 17.938846588134766\n",
      "Epoch 317 - Training loss: 9.767732620239258 - Validation loss: 17.667936325073242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 318 - Training loss: 8.43934440612793: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 54.59it/s]\n",
      "Epoch 319 - Training loss: 37.24720001220703: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.03it/s]\n",
      "Epoch 320 - Training loss: 29.29928207397461: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.72it/s]\n",
      "Epoch 321 - Training loss: 11.575057983398438: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 57.02it/s]\n",
      "Epoch 322 - Training loss: 22.65363311767578: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.84it/s]\n",
      "Epoch 323 - Training loss: 11.560836791992188:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318 - Training loss: 9.756063461303711 - Validation loss: 17.180438995361328\n",
      "Epoch 319 - Training loss: 24.742538452148438 - Validation loss: 17.49871826171875\n",
      "Epoch 320 - Training loss: 18.84222412109375 - Validation loss: 17.265682220458984\n",
      "Epoch 321 - Training loss: 12.221866607666016 - Validation loss: 16.65435791015625\n",
      "Epoch 322 - Training loss: 16.559288024902344 - Validation loss: 16.842098236083984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 323 - Training loss: 17.391986846923828: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.70it/s]\n",
      "Epoch 324 - Training loss: 17.903852462768555: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.27it/s]\n",
      "Epoch 325 - Training loss: 15.135215759277344: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.88it/s]\n",
      "Epoch 326 - Training loss: 6.868041515350342: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.30it/s]\n",
      "Epoch 327 - Training loss: 12.569659233093262: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.13it/s]\n",
      "Epoch 328 - Training loss: 9.587940216064453:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323 - Training loss: 14.476411819458008 - Validation loss: 16.972970962524414\n",
      "Epoch 324 - Training loss: 13.263551712036133 - Validation loss: 17.296676635742188\n",
      "Epoch 325 - Training loss: 11.073934555053711 - Validation loss: 17.62543296813965\n",
      "Epoch 326 - Training loss: 9.023119926452637 - Validation loss: 18.280197143554688\n",
      "Epoch 327 - Training loss: 12.926216125488281 - Validation loss: 19.63033676147461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 328 - Training loss: 10.682116508483887: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.19it/s]\n",
      "Epoch 329 - Training loss: 26.3353271484375: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 56.50it/s]\n",
      "Epoch 330 - Training loss: 13.964359283447266: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.51it/s]\n",
      "Epoch 331 - Training loss: 9.20447063446045: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.74it/s]\n",
      "Epoch 332 - Training loss: 9.297965049743652: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.26it/s]\n",
      "Epoch 333 - Training loss: 12.36036491394043:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328 - Training loss: 10.135028839111328 - Validation loss: 20.936019897460938\n",
      "Epoch 329 - Training loss: 19.59304428100586 - Validation loss: 21.883445739746094\n",
      "Epoch 330 - Training loss: 13.300848960876465 - Validation loss: 21.85107421875\n",
      "Epoch 331 - Training loss: 10.828872680664062 - Validation loss: 20.90707015991211\n",
      "Epoch 332 - Training loss: 9.560708045959473 - Validation loss: 20.412572860717773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 333 - Training loss: 3.2968544960021973: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.40it/s]\n",
      "Epoch 334 - Training loss: 21.18706512451172: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.17it/s]\n",
      "Epoch 335 - Training loss: 7.291438579559326: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.67it/s]\n",
      "Epoch 336 - Training loss: 10.900961875915527: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.92it/s]\n",
      "Epoch 337 - Training loss: 10.26909351348877: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.10it/s]\n",
      "Epoch 338 - Training loss: 15.549291610717773:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333 - Training loss: 7.828609466552734 - Validation loss: 19.771520614624023\n",
      "Epoch 334 - Training loss: 14.630184173583984 - Validation loss: 18.899452209472656\n",
      "Epoch 335 - Training loss: 9.990354537963867 - Validation loss: 18.011947631835938\n",
      "Epoch 336 - Training loss: 10.074699401855469 - Validation loss: 17.266220092773438\n",
      "Epoch 337 - Training loss: 10.814631462097168 - Validation loss: 17.14898681640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 338 - Training loss: 4.59871768951416: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 56.21it/s]\n",
      "Epoch 339 - Training loss: 14.353446960449219: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.43it/s]\n",
      "Epoch 340 - Training loss: 6.501168727874756: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.59it/s]\n",
      "Epoch 341 - Training loss: 11.058914184570312: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.25it/s]\n",
      "Epoch 342 - Training loss: 8.956499099731445: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.71it/s]\n",
      "Epoch 343 - Training loss: 13.619277000427246:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338 - Training loss: 10.074005126953125 - Validation loss: 17.02252769470215\n",
      "Epoch 339 - Training loss: 13.027769088745117 - Validation loss: 17.429025650024414\n",
      "Epoch 340 - Training loss: 7.563620567321777 - Validation loss: 17.20063591003418\n",
      "Epoch 341 - Training loss: 10.86694049835205 - Validation loss: 16.7418270111084\n",
      "Epoch 342 - Training loss: 10.329584121704102 - Validation loss: 16.431442260742188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 343 - Training loss: 14.738025665283203: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.67it/s]\n",
      "Epoch 344 - Training loss: 19.55809783935547: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.05it/s]\n",
      "Epoch 345 - Training loss: 8.333272933959961: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.65it/s]\n",
      "Epoch 346 - Training loss: 6.922299861907959: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.66it/s]\n",
      "Epoch 347 - Training loss: 17.456573486328125: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.99it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343 - Training loss: 14.178651809692383 - Validation loss: 16.70112419128418\n",
      "Epoch 344 - Training loss: 14.687708854675293 - Validation loss: 17.451271057128906\n",
      "Epoch 345 - Training loss: 10.083099365234375 - Validation loss: 18.488155364990234\n",
      "Epoch 346 - Training loss: 8.56838321685791 - Validation loss: 19.4451961517334\n",
      "Epoch 347 - Training loss: 13.003698348999023 - Validation loss: 20.660947799682617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 348 - Training loss: 10.527458190917969: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.08it/s]\n",
      "Epoch 349 - Training loss: 9.418550491333008: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.37it/s]\n",
      "Epoch 350 - Training loss: 9.439613342285156: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.71it/s]\n",
      "Epoch 351 - Training loss: 16.619434356689453: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.52it/s]\n",
      "Epoch 352 - Training loss: 19.014083862304688: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.28it/s]\n",
      "Epoch 353 - Training loss: 10.583662033081055:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348 - Training loss: 11.58908748626709 - Validation loss: 20.374860763549805\n",
      "Epoch 349 - Training loss: 9.35310173034668 - Validation loss: 20.740663528442383\n",
      "Epoch 350 - Training loss: 9.818902015686035 - Validation loss: 20.488338470458984\n",
      "Epoch 351 - Training loss: 13.135039329528809 - Validation loss: 19.867198944091797\n",
      "Epoch 352 - Training loss: 15.237205505371094 - Validation loss: 19.01528549194336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 353 - Training loss: 7.864463806152344: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.19it/s]\n",
      "Epoch 354 - Training loss: 9.701294898986816: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 53.10it/s]\n",
      "Epoch 355 - Training loss: 6.803382873535156: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.57it/s]\n",
      "Epoch 356 - Training loss: 32.55157470703125: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.41it/s]\n",
      "Epoch 357 - Training loss: 10.047941207885742: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.36it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353 - Training loss: 9.2240629196167 - Validation loss: 18.02140998840332\n",
      "Epoch 354 - Training loss: 9.969171524047852 - Validation loss: 17.792320251464844\n",
      "Epoch 355 - Training loss: 10.09051513671875 - Validation loss: 17.745872497558594\n",
      "Epoch 356 - Training loss: 21.411256790161133 - Validation loss: 17.469398498535156\n",
      "Epoch 357 - Training loss: 9.296612739562988 - Validation loss: 17.53803062438965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 358 - Training loss: 9.243921279907227: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.82it/s]\n",
      "Epoch 359 - Training loss: 10.209936141967773: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 52.79it/s]\n",
      "Epoch 360 - Training loss: 5.998282432556152: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.63it/s]\n",
      "Epoch 361 - Training loss: 19.770061492919922: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.56it/s]\n",
      "Epoch 362 - Training loss: 4.805887699127197: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 50.38it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358 - Training loss: 10.270454406738281 - Validation loss: 18.2546443939209\n",
      "Epoch 359 - Training loss: 9.94487476348877 - Validation loss: 18.898929595947266\n",
      "Epoch 360 - Training loss: 10.296119689941406 - Validation loss: 18.827987670898438\n",
      "Epoch 361 - Training loss: 16.332290649414062 - Validation loss: 18.919771194458008\n",
      "Epoch 362 - Training loss: 8.767496109008789 - Validation loss: 18.297927856445312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 363 - Training loss: 4.65371561050415: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.63it/s]\n",
      "Epoch 364 - Training loss: 8.585103034973145: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.33it/s]\n",
      "Epoch 365 - Training loss: 20.059518814086914: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.97it/s]\n",
      "Epoch 366 - Training loss: 29.60364532470703: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.03it/s]\n",
      "Epoch 367 - Training loss: 15.917623519897461: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.34it/s]\n",
      "Epoch 368 - Training loss: 9.265830993652344:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363 - Training loss: 6.79823112487793 - Validation loss: 17.537372589111328\n",
      "Epoch 364 - Training loss: 10.24026107788086 - Validation loss: 17.126005172729492\n",
      "Epoch 365 - Training loss: 13.4271879196167 - Validation loss: 17.587989807128906\n",
      "Epoch 366 - Training loss: 19.99580955505371 - Validation loss: 17.518877029418945\n",
      "Epoch 367 - Training loss: 13.855348587036133 - Validation loss: 16.88455581665039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 368 - Training loss: 17.05938720703125: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.34it/s]\n",
      "Epoch 369 - Training loss: 17.08426856994629: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.31it/s]\n",
      "Epoch 370 - Training loss: 16.151039123535156: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.27it/s]\n",
      "Epoch 371 - Training loss: 10.979337692260742: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.37it/s]\n",
      "Epoch 372 - Training loss: 10.687631607055664: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.00it/s]\n",
      "Epoch 373 - Training loss: 7.989242076873779:   0%|                                           | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368 - Training loss: 13.162609100341797 - Validation loss: 16.93230628967285\n",
      "Epoch 369 - Training loss: 13.276615142822266 - Validation loss: 17.31968879699707\n",
      "Epoch 370 - Training loss: 13.728260040283203 - Validation loss: 17.662235260009766\n",
      "Epoch 371 - Training loss: 11.904616355895996 - Validation loss: 18.37993812561035\n",
      "Epoch 372 - Training loss: 11.84097957611084 - Validation loss: 18.449861526489258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 373 - Training loss: 10.939997673034668: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.47it/s]\n",
      "Epoch 374 - Training loss: 11.126895904541016: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 55.54it/s]\n",
      "Epoch 375 - Training loss: 6.550200462341309: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.78it/s]\n",
      "Epoch 376 - Training loss: 33.870018005371094: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.60it/s]\n",
      "Epoch 377 - Training loss: 11.851698875427246: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.15it/s]\n",
      "Epoch 378 - Training loss: 13.361983299255371:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373 - Training loss: 9.464619636535645 - Validation loss: 18.135202407836914\n",
      "Epoch 374 - Training loss: 11.133347511291504 - Validation loss: 17.892742156982422\n",
      "Epoch 375 - Training loss: 7.338693141937256 - Validation loss: 17.202001571655273\n",
      "Epoch 376 - Training loss: 22.775375366210938 - Validation loss: 17.344614028930664\n",
      "Epoch 377 - Training loss: 10.127641677856445 - Validation loss: 17.647172927856445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 378 - Training loss: 9.615196228027344: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.86it/s]\n",
      "Epoch 379 - Training loss: 11.199851036071777: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.32it/s]\n",
      "Epoch 380 - Training loss: 5.804842948913574: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.78it/s]\n",
      "Epoch 381 - Training loss: 23.935422897338867: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.48it/s]\n",
      "Epoch 382 - Training loss: 16.443571090698242: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 56.04it/s]\n",
      "Epoch 383 - Training loss: 12.619309425354004:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378 - Training loss: 11.488590240478516 - Validation loss: 17.158138275146484\n",
      "Epoch 379 - Training loss: 9.72359848022461 - Validation loss: 16.878942489624023\n",
      "Epoch 380 - Training loss: 9.121198654174805 - Validation loss: 16.408979415893555\n",
      "Epoch 381 - Training loss: 17.652278900146484 - Validation loss: 15.802018165588379\n",
      "Epoch 382 - Training loss: 12.933611869812012 - Validation loss: 15.648691177368164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 383 - Training loss: 20.673919677734375: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 45.17it/s]\n",
      "Epoch 384 - Training loss: 8.050117492675781: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 46.96it/s]\n",
      "Epoch 385 - Training loss: 23.517202377319336: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 53.76it/s]\n",
      "Epoch 386 - Training loss: 8.530935287475586: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.22it/s]\n",
      "Epoch 387 - Training loss: 9.375125885009766: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 54.62it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383 - Training loss: 16.64661407470703 - Validation loss: 15.446208953857422\n",
      "Epoch 384 - Training loss: 9.037851333618164 - Validation loss: 15.1284818649292\n",
      "Epoch 385 - Training loss: 17.244686126708984 - Validation loss: 15.001842498779297\n",
      "Epoch 386 - Training loss: 10.385912895202637 - Validation loss: 15.171070098876953\n",
      "Epoch 387 - Training loss: 12.119890213012695 - Validation loss: 15.705476760864258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 388 - Training loss: 9.896190643310547: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.22it/s]\n",
      "Epoch 389 - Training loss: 17.21474266052246: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.23it/s]\n",
      "Epoch 390 - Training loss: 8.543855667114258: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.60it/s]\n",
      "Epoch 391 - Training loss: 8.911859512329102: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.48it/s]\n",
      "Epoch 392 - Training loss: 8.955062866210938: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 56.18it/s]\n",
      "Epoch 393 - Training loss: 10.772300720214844:   0%|                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388 - Training loss: 12.12100601196289 - Validation loss: 16.34530258178711\n",
      "Epoch 389 - Training loss: 13.381879806518555 - Validation loss: 16.978267669677734\n",
      "Epoch 390 - Training loss: 8.723334312438965 - Validation loss: 18.012990951538086\n",
      "Epoch 391 - Training loss: 10.646793365478516 - Validation loss: 18.47659683227539\n",
      "Epoch 392 - Training loss: 8.700498580932617 - Validation loss: 18.167831420898438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 393 - Training loss: 6.55209493637085: 100%|████████████████████████████████████| 2/2 [00:00<00:00, 55.30it/s]\n",
      "Epoch 394 - Training loss: 11.92062759399414: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 55.25it/s]\n",
      "Epoch 395 - Training loss: 15.206777572631836: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.90it/s]\n",
      "Epoch 396 - Training loss: 5.135056495666504: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 51.39it/s]\n",
      "Epoch 397 - Training loss: 16.66432762145996: 100%|███████████████████████████████████| 2/2 [00:00<00:00, 52.38it/s]\n",
      "  0%|                                                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393 - Training loss: 8.662198066711426 - Validation loss: 18.268199920654297\n",
      "Epoch 394 - Training loss: 12.334908485412598 - Validation loss: 18.231468200683594\n",
      "Epoch 395 - Training loss: 12.585148811340332 - Validation loss: 17.7148494720459\n",
      "Epoch 396 - Training loss: 8.049286842346191 - Validation loss: 17.236398696899414\n",
      "Epoch 397 - Training loss: 15.363054275512695 - Validation loss: 16.445581436157227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 398 - Training loss: 10.855856895446777: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 54.46it/s]\n",
      "Epoch 399 - Training loss: 11.325026512145996: 100%|██████████████████████████████████| 2/2 [00:00<00:00, 47.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398 - Training loss: 10.398223876953125 - Validation loss: 16.20722198486328\n",
      "Epoch 399 - Training loss: 12.503231048583984 - Validation loss: 15.918633460998535\n",
      "Best Epoch 177 - Best Validation loss: 14.74407958984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "max_epoch = 400\n",
    "best_loss = 1e10\n",
    "best_finetune_model = None\n",
    "best_epoch = 0\n",
    "device = \"cuda\"\n",
    "finetune_model.to(device)\n",
    "while i < max_epoch:\n",
    "    train_loss = []\n",
    "    progress_bar = tqdm(train_dataloader)\n",
    "    \n",
    "    for IDs in progress_bar:\n",
    "        finetune_model.train()\n",
    "        X = torch.tensor(data.feature_df.loc[IDs].to_numpy()).to(device)\n",
    "        X = X.reshape(-1, max_len, X.shape[-1])\n",
    "        targets = torch.tensor(data.labels_df.loc[IDs].to_numpy()).to(device)\n",
    "        pred = finetune_model.predict(X.float()).squeeze(-1)\n",
    "        loss = loss_fn(pred, targets)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(finetune_model.parameters(), max_norm=4.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_description(\"Epoch {} - Training loss: {}\".format(i, loss)) \n",
    "        train_loss.append(loss)\n",
    "    \n",
    "    val_loss = []\n",
    "    for IDs in val_dataloader:\n",
    "        finetune_model.eval()\n",
    "        X = torch.tensor(data.feature_df.loc[IDs].to_numpy()).to(device)\n",
    "        X = X.reshape(-1, max_len, X.shape[-1])\n",
    "        targets = torch.tensor(data.labels_df.loc[IDs].to_numpy()).to(device)\n",
    "        pred = finetune_model.predict(X.float()).squeeze(-1)\n",
    "        loss = loss_fn(pred, targets)\n",
    "        val_loss.append(loss)\n",
    "    \n",
    "    train_loss = torch.tensor(train_loss).mean()\n",
    "    val_loss = torch.tensor(val_loss).mean()\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_finetune_model = copy.deepcopy(finetune_model)\n",
    "        best_epoch = i\n",
    "    \n",
    "    progress_bar.write(\"Epoch {} - Training loss: {} - Validation loss: {}\".format(i, train_loss, val_loss))\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "tqdm.write(\"Best Epoch {} - Best Validation loss: {}\".format(best_epoch, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 20.3616943359375\n",
      "Test loss: 4.512393474578857\n"
     ]
    }
   ],
   "source": [
    "test_loss = []\n",
    "for IDs in test_dataloader:\n",
    "    best_finetune_model.eval()\n",
    "    X = torch.tensor(test_data.feature_df.loc[IDs].to_numpy()).to(device)\n",
    "    X = X.reshape(-1, max_len, X.shape[-1])\n",
    "    targets = torch.tensor(test_data.labels_df.loc[IDs].to_numpy()).to(device)\n",
    "    pred = best_finetune_model.predict(X.float()).squeeze(-1)\n",
    "    loss = loss_fn(pred, targets)\n",
    "    test_loss.append(loss)\n",
    "\n",
    "\n",
    "test_loss = torch.tensor(test_loss).mean()\n",
    "print(\"Test loss: {}\".format(test_loss))\n",
    "print(\"Test loss: {}\".format(np.sqrt(test_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Results from the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../img/img_7.PNG\"/><center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "1. https://arxiv.org/abs/2302.00861\n",
    "2. https://github.com/gzerveas/mvts_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Pretrain\n",
    "\n",
    "Test loss: 17.563016891479492\n",
    "\n",
    "Test loss: 24.951457977294922\n",
    "\n",
    "Test loss: 13.356301307678223\n",
    "\n",
    "Test loss: 15.543647766113281\n",
    "\n",
    "Test loss: 10.70577621459961\n",
    "\n",
    "Test loss: 11.653989791870117\n",
    "\n",
    "Test loss: 28.348876953125\n",
    "\n",
    "Test loss: 9.66756534576416\n",
    "\n",
    "Test loss: 22.540130615234375\n",
    "\n",
    "Test loss: 20.3616943359375\n",
    "\n",
    "Pretrain L//2 pretrain epoch 50\n",
    "\n",
    "Test loss: 11.152569770812988\n",
    "\n",
    "Test loss: 8.513360023498535\n",
    "\n",
    "Test loss: 20.0480899810791\n",
    "\n",
    "Test loss: 12.694931983947754\n",
    "\n",
    "Test loss: 15.458633422851562\n",
    "\n",
    "Test loss: 16.706832885742188\n",
    "\n",
    "Test loss: 11.432455062866211\n",
    "\n",
    "Test loss: 7.263433456420898\n",
    "\n",
    "Test loss: 15.908415794372559\n",
    "\n",
    "Test loss: 17.736656188964844\n",
    "\n",
    "Pretrain L//2 pretrain epoch 20\n",
    "\n",
    "Test loss: 13.188956260681152\n",
    "\n",
    "Test loss: 12.610322952270508\n",
    "\n",
    "Test loss: 22.47460174560547\n",
    "\n",
    "Test loss: 17.15345001220703\n",
    "\n",
    "Test loss: 20.823780059814453\n",
    "\n",
    "Pretrain L//2 pretrain epoch 100\n",
    "\n",
    "Test loss: 20.534494400024414\n",
    "\n",
    "Test loss: 25.885923385620117\n",
    "\n",
    "Test loss: 21.357059478759766\n",
    "\n",
    "Test loss: 20.61741828918457\n",
    "\n",
    "Test loss: 24.453622817993164\n",
    "\n",
    "Pretrain L//4 pretrain epoch 50\n",
    "\n",
    "Test loss: 8.65383243560791\n",
    "\n",
    "Test loss: 7.952672481536865\n",
    "\n",
    "Test loss: 13.125472068786621\n",
    "\n",
    "Test loss: 17.975181579589844\n",
    "\n",
    "Test loss: 21.050844192504883\n",
    "\n",
    "Test loss: 9.025917053222656\n",
    "\n",
    "Test loss: 13.526683807373047\n",
    "\n",
    "Test loss: 16.005821228027344\n",
    "\n",
    "Test loss: 23.140092849731445\n",
    "\n",
    "Test loss: 11.915889739990234\n",
    "\n",
    "Pretrain L//10 pretrain epoch 50\n",
    "\n",
    "Test loss: 18.413068771362305\n",
    "\n",
    "Test loss: 17.07589340209961\n",
    "\n",
    "Test loss: 14.856538772583008\n",
    "\n",
    "Test loss: 9.033221244812012\n",
    "\n",
    "Test loss: 16.976844787597656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
